{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "ypOtqHe7gr3i"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GGqJn9-15sOU",
        "outputId": "c62913fb-dff8-4a68-b50e-4898509be31c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (22.02.0-2ubuntu0.6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 31 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 31 not upgraded.\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.11/dist-packages (1.0.2)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (11.1.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (3.2.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (4.12.2)\n",
            "Collecting gensim==3.8.3\n",
            "  Using cached gensim-3.8.3.tar.gz (23.4 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.11/dist-packages (from gensim==3.8.3) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.11/dist-packages (from gensim==3.8.3) (1.14.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from gensim==3.8.3) (1.17.0)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim==3.8.3) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart_open>=1.8.1->gensim==3.8.3) (1.17.2)\n",
            "Building wheels for collected packages: gensim\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for gensim (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for gensim\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for gensim\n",
            "Failed to build gensim\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (gensim)\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: keybert in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from keybert) (1.26.4)\n",
            "Requirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.11/dist-packages (from keybert) (13.9.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.11/dist-packages (from keybert) (1.6.1)\n",
            "Requirement already satisfied: sentence-transformers>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from keybert) (3.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.4.0->keybert) (2.18.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (3.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.48.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (2.5.1+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.28.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2025.1.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: google_images_download in /usr/local/lib/python3.11/dist-packages (2.8.0)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (from google_images_download) (4.29.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium->google_images_download) (2.3.0)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.11/dist-packages (from selenium->google_images_download) (0.29.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.11/dist-packages (from selenium->google_images_download) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium->google_images_download) (2025.1.31)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium->google_images_download) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium->google_images_download) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google_images_download) (25.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google_images_download) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google_images_download) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google_images_download) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google_images_download) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.9->selenium->google_images_download) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium->google_images_download) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->google_images_download) (0.14.0)\n",
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.11/dist-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2025.1.31)\n",
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "texlive-fonts-extra is already the newest version (2021.20220204-1).\n",
            "texlive-fonts-recommended is already the newest version (2021.20220204-1).\n",
            "texlive-latex-base is already the newest version (2021.20220204-1).\n",
            "texlive-latex-extra is already the newest version (2021.20220204-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 31 not upgraded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade langchain openai  -q\n",
        "!pip install sentence_transformers -q\n",
        "!apt-get install poppler-utils\n",
        "!apt-get install -y tesseract-ocr\n",
        "!pip install -U langchain-community -q\n",
        "!pip install pillow\n",
        "!pip install requests\n",
        "!pip install python-pptx\n",
        "!pip install gensim==3.8.3\n",
        "!pip install keybert\n",
        "!pip install requests Pillow\n",
        "!pip install google_images_download\n",
        "!pip install google-search-results\n",
        "!pip install groq\n",
        "!pip install PyPDF2\n",
        "!pip install pinecone -q\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install texlive-latex-base texlive-fonts-recommended texlive-fonts-extra texlive-latex-extra\n",
        "\n",
        "from pptx import Presentation\n",
        "from pptx.util import Pt, Inches\n",
        "from PIL import Image\n",
        "import random\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "import requests\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Initialize KeyBERT\n",
        "from keybert import KeyBERT\n",
        "kw_model = KeyBERT()\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Vector DB Connection"
      ],
      "metadata": {
        "id": "7wSi9GiD61a5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_pinecone\n",
        "import getpass\n",
        "import os\n",
        "import time\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain_pinecone import Pinecone as LangchainPinecone  # Correct import\n",
        "\n",
        "#074e0d9a-ab5e-48bf-8eae-9effae335521\n",
        "# Pinecone API key\n",
        "os.environ[\"PINECONE_API_KEY\"] = \"074e0d9a-ab5e-48bf-8eae-9effae335521\"\n",
        "if not os.getenv(\"PINECONE_API_KEY\"):\n",
        "    os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Enter your Pinecone API key: \")\n",
        "\n",
        "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
        "\n",
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=pinecone_api_key)\n",
        "\n",
        "# Define your index name\n",
        "index_name = \"newdata\"  # Change if desired\n",
        "\n",
        "# Check for existing indexes\n",
        "existing_indexes = [index_info.name for index_info in pc.list_indexes()]\n",
        "\n",
        "# Create the index if it does not exist\n",
        "if index_name not in existing_indexes:\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=384,  # Adjust this to match your embeddings' dimension\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        "    )\n",
        "\n",
        "    # Wait until the index is ready\n",
        "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
        "        print(\"Waiting for the index to be ready...\")\n",
        "        time.sleep(1)\n",
        "\n",
        "# Connect to the index as a Pinecone instance\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "# Print connection success message\n",
        "print(f\"Successfully connected to the index: {index_name}\")\n",
        "\n",
        "# Define embeddings model\n",
        "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Correct way to create LangChain Pinecone index\n",
        "langchain_index = LangchainPinecone(\n",
        "    index=index,  # Pass the correct Pinecone instance\n",
        "    embedding=embeddings,\n",
        "    text_key=\"text\"  # Required argument for storing/retrieving text\n",
        ")\n",
        "\n",
        "# Output verification\n",
        "print(f\"Successfully created or connected to the LangChain index: {langchain_index}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKOH7YaS6ngt",
        "outputId": "d14fc52e-cbb6-40f5-f825-a8558a70cc1e",
        "collapsed": true
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_pinecone in /usr/local/lib/python3.11/dist-packages (0.2.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain_pinecone) (0.3.43)\n",
            "Requirement already satisfied: pinecone<6.0.0,>=5.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_pinecone) (5.4.2)\n",
            "Requirement already satisfied: aiohttp<3.11,>=3.10 in /usr/local/lib/python3.11/dist-packages (from langchain_pinecone) (3.10.11)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain_pinecone) (1.26.4)\n",
            "Requirement already satisfied: langchain-tests<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain_pinecone) (0.3.14)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (2.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain_pinecone) (1.18.3)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (0.3.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (2.10.6)\n",
            "Requirement already satisfied: pytest<9,>=7 in /usr/local/lib/python3.11/dist-packages (from langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (8.3.5)\n",
            "Requirement already satisfied: pytest-asyncio<1,>=0.20 in /usr/local/lib/python3.11/dist-packages (from langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (0.25.3)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (0.28.1)\n",
            "Requirement already satisfied: syrupy<5,>=4 in /usr/local/lib/python3.11/dist-packages (from langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (4.9.0)\n",
            "Requirement already satisfied: pytest-socket<1,>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (0.7.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (2025.1.31)\n",
            "Requirement already satisfied: pinecone-plugin-inference<4.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (3.1.0)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (2.8.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain_pinecone) (2.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (2.27.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (1.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone<6.0.0,>=5.4.0->langchain_pinecone) (1.17.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<3.11,>=3.10->langchain_pinecone) (0.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain_pinecone) (1.3.1)\n",
            "Successfully connected to the index: newdata\n",
            "Successfully created or connected to the LangChain index: <langchain_pinecone.vectorstores.Pinecone object at 0x792e296a34d0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Relevant Document Extraction from Vector DB"
      ],
      "metadata": {
        "id": "bEXSDIJ28Les"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similar_docs(query, k=20, score=True):\n",
        "    if score:\n",
        "        similar_docs = langchain_index.similarity_search_with_score(query, k=k)  # Use langchain_index\n",
        "    else:\n",
        "        similar_docs = langchain_index.similarity_search(query, k=k)  # Use langchain_index\n",
        "    return similar_docs"
      ],
      "metadata": {
        "id": "cuW91hQJ6wAB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extraction of answer from LLM"
      ],
      "metadata": {
        "id": "gohwsqLA84BP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################  WITH GROQ #############################################################\n",
        "from groq import Groq\n",
        "import os\n",
        "\n",
        "class GroqClient:\n",
        "    def __init__(self, api_key):\n",
        "        self.client = Groq(api_key=api_key)\n",
        "\n",
        "    def get_completion(self, query, content ,max_tokens=3500):\n",
        "        prompt = self._construct_prompt(query, content)\n",
        "\n",
        "        try:\n",
        "            chat_completion = self.client.chat.completions.create(\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are a helpful AI assistant specialized in providing detailed technical explanations.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": prompt\n",
        "                    }\n",
        "                ],\n",
        "                model=\"deepseek-r1-distill-llama-70b\",\n",
        "                temperature=0.5,\n",
        "                max_tokens=max_tokens,\n",
        "                top_p=0.9,\n",
        "                stream=False\n",
        "            )\n",
        "            return chat_completion.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"API request failed: {str(e)}\")\n",
        "\n",
        "    def _construct_prompt(self, query, content):\n",
        "        return f'''\n",
        "Question: {query}\n",
        "\n",
        "Content: {content}\n",
        "\n",
        "\n",
        "Provide a comprehensive explanation strictly following this structure. Always use \"##\" to introduce each section:\n",
        "\n",
        "## 1. **Concept Overview**\n",
        "  • Core definition and purpose\n",
        "  • Key principles\n",
        "  • Relationship to broader computing concepts\n",
        "\n",
        "## 2. **Technical Components**\n",
        "  • Primary elements and their roles\n",
        "  • Relationships and interactions\n",
        "  • Implementation details\n",
        "  • Mathematical Equations\n",
        "  • Core algorithms/procedures (if applicable)\n",
        "\n",
        "## 3. **Working Mechanism**\n",
        "  • Step-by-step operational flow\n",
        "  • Critical processes and transformations\n",
        "  • Resource management (if applicable)\n",
        "  • Exception handling (if applicable)\n",
        "\n",
        "## 4. **Implementation Example**\n",
        "  • Use case scenario\n",
        "  • Code implementation or technical design\n",
        "  • Step-by-step execution\n",
        "  • Output analysis\n",
        "\n",
        "## 5. **Best Practices**\n",
        "  • Design considerations\n",
        "  • Optimization techniques\n",
        "  • Common pitfalls\n",
        "  • Performance implications\n",
        "\n",
        "## 6. **Applications**\n",
        "  • Real-world use cases\n",
        "  • Industry applications\n",
        "  • Integration patterns\n",
        "  • Variations and alternatives\n",
        "\n",
        "## 7. **Evaluation**\n",
        "  • Performance metrics\n",
        "  • Testing approaches\n",
        "  • Debugging strategies\n",
        "  • Optimization opportunities\n",
        "\n",
        "## 8. **Practice Problems**\n",
        "  • Concept verification questions\n",
        "  • Implementation challenges\n",
        "  • Problem-solving scenarios\n",
        "  • Solutions with explanations\n",
        "\n",
        "### Format Requirements:\n",
        "- Always use \"##\" to introduce each section header. Avoid using any other format.\n",
        "- Use bullet points for clarity\n",
        "- Show all mathematical steps using proper equation formatting ($...$)\n",
        "- Include clear variable definitions after each equation\n",
        "- Write formulas using LaTeX formatting inside $...$\n",
        "- For matrices use: $\\begin{{bmatrix}} a & b \\\\ c & d \\end{{bmatrix}}$\n",
        "- For fractions use: $\\frac{{numerator}}{{denominator}}$\n",
        "- Use ■ for numbered equations and • for regular points\n",
        "- Demonstrate practical interpretation\n",
        "- Connect to real applications\n",
        "\n",
        "### Equation Guidelines:\n",
        "- Enclose equations in $...$ format\n",
        "- Use proper LaTeX notation for mathematical expressions\n",
        "- Use $\\sum$ for summations\n",
        "- Define each variable after presenting equations\n",
        "- Number important equations using ■\n",
        "- Show step-by-step derivations with clear explanations\n",
        "\n",
        "### Code Guidelines:\n",
        "- Use LaTeX verbatim environment for code blocks:\n",
        "  \\begin{{verbatim}}\n",
        "  code here\n",
        "  \\end{{verbatim}}\n",
        "\n",
        "- For inline code use \\texttt{{code}}\n",
        "- For syntax highlighting:\n",
        "  \\begin{{lstlisting}}[language=Python]\n",
        "  code here\n",
        "  \\end{{lstlisting}}\n",
        "- Include comments explaining code functionality\n",
        "- Show output examples where applicable\n",
        "'''\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # api_key = os.environ.get(\"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\")\n",
        "    # client = GroqClient(api_key)\n",
        "    query = \"LSTM\"\n",
        "    content = get_similar_docs(query)\n",
        "\n",
        "    os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
        "    api_key = os.environ.get(\"GROQ_API_KEY\")\n",
        "    client = GroqClient(api_key)\n",
        "\n",
        "    try:\n",
        "        answer = client.get_completion(query, content)\n",
        "        print(\"Answer:\", answer)\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", str(e))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hjVf3WYa9DbJ",
        "outputId": "24e674c9-a8eb-4633-f7e5-2d53391ea672"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: <think>\n",
            "Okay, so I need to explain LSTM based on the provided content. Let me start by understanding what the user is asking for. They want a comprehensive explanation of LSTM following a specific structure with eight sections. Each section has its own points, and they want me to use \"##\" for headers and bullet points. They also provided a lot of content from various documents, which I can use as a reference.\n",
            "\n",
            "First, I'll look through the documents to gather information about LSTM. I see mentions of Graves, Hochreiter, and Schmidhuber, which I remember are key researchers in LSTM development. The documents talk about the limitations of traditional RNNs, like the vanishing gradient problem, and how LSTMs address this with memory cells and gates. There's also discussion on the components of LSTM, such as input, output, and forget gates, and how they interact.\n",
            "\n",
            "For the concept overview, I should define what LSTM is, its purpose, key principles, and how it relates to other computing concepts like RNNs and deep learning. I'll mention the memory cells and gates as core components.\n",
            "\n",
            "Moving on to technical components, I need to detail each part: memory cells, input gate, output gate, forget gate. I should explain their roles and how they interact. Including the mathematical equations for each gate and the cell state will be important. I'll make sure to define each variable clearly after each equation.\n",
            "\n",
            "In the working mechanism section, I'll outline the steps LSTM takes during forward propagation, including input processing, gate computations, cell state update, and output generation. I'll also touch on backpropagation and BPTT, explaining how gradients are computed and weights are updated.\n",
            "\n",
            "For the implementation example, I'll create a simple use case, maybe a text classification task. I'll provide a code example using PyTorch, showing how to set up an LSTM model, process inputs, and train it. I'll include comments to explain each part of the code.\n",
            "\n",
            "Best practices should cover design considerations like choosing the right number of layers and cells, optimization techniques such as gradient clipping, and common pitfalls like overfitting. I'll explain each point clearly, relating them to LSTM's specific characteristics.\n",
            "\n",
            "Applications will cover real-world uses like language modeling, translation, and time series prediction. I'll also mention variations like BiLSTM and Transformer models, explaining how they integrate with LSTM concepts.\n",
            "\n",
            "Evaluation will discuss metrics like accuracy and perplexity, testing approaches, and how to debug issues like vanishing gradients. I'll also talk about optimization opportunities, such as using pre-trained models.\n",
            "\n",
            "Finally, practice problems will include questions to verify understanding, implementation challenges, and problem-solving scenarios. I'll provide solutions with explanations to help reinforce the concepts.\n",
            "\n",
            "I need to make sure each section is concise, uses bullet points, and includes equations where necessary. I'll avoid using markdown and stick to the specified format. I'll also ensure that each equation is properly formatted with LaTeX and that variables are clearly defined. The code example should be in a verbatim block with syntax highlighting if possible.\n",
            "\n",
            "I should also connect the explanations to real applications to show the practical relevance of LSTMs. This will help the user understand not just the theory but also how it's applied in industry and research.\n",
            "\n",
            "Overall, I need to be thorough but clear, making sure each section flows logically into the next. I'll double-check that I cover all the points the user specified and that the content aligns with the provided documents. This way, the user gets a comprehensive and structured explanation of LSTM that meets their requirements.\n",
            "</think>\n",
            "\n",
            "## 1. **Concept Overview**\n",
            "- **Core Definition and Purpose**:  \n",
            "  Long Short-Term Memory (LSTM) networks are a type of Recurrent Neural Network (RNN) designed to handle the vanishing gradient problem in traditional RNNs. They are primarily used for sequence modeling tasks, such as language modeling, speech recognition, and time-series prediction.  \n",
            "- **Key Principles**:  \n",
            "  - LSTMs introduce memory cells and gates (input, output, and forget gates) to control the flow of information.  \n",
            "  - These components allow the network to learn long-term dependencies by selectively retaining or discarding information.  \n",
            "- **Relationship to Broader Computing Concepts**:  \n",
            "  - LSTMs are a part of deep learning and neural networks, extending the capabilities of RNNs.  \n",
            "  - They are particularly useful for sequential data, where temporal relationships are important.\n",
            "\n",
            "## 2. **Technical Components**\n",
            "- **Primary Elements and Their Roles**:  \n",
            "  - **Memory Cell (Cell State)**: Acts as the internal memory of the LSTM, storing information over long sequences.  \n",
            "  - **Input Gate**: Controls the flow of new information into the memory cell.  \n",
            "  - **Output Gate**: Controls the output based on the memory cell and the hidden state.  \n",
            "  - **Forget Gate**: Determines what information to discard from the previous hidden state.  \n",
            "- **Relationships and Interactions**:  \n",
            "  - The gates interact to regulate the memory cell's state, ensuring that only relevant information is retained or updated.  \n",
            "- **Implementation Details**:  \n",
            "  - The LSTM architecture consists of multiple layers, with each layer containing memory cells and gates.  \n",
            "- **Mathematical Equations**:  \n",
            "  Let \\( f_t \\), \\( i_t \\), and \\( o_t \\) represent the forget, input, and output gates, respectively. Let \\( c_t \\) and \\( h_t \\) denote the cell state and hidden state at time \\( t \\). The key equations are:  \n",
            "  ■ \\( f_t = \\sigma(W_f x_t + U_f h_{t-1} + b_f) \\)  \n",
            "  ■ \\( i_t = \\sigma(W_i x_t + U_i h_{t-1} + b_i) \\)  \n",
            "  ■ \\( o_t = \\sigma(W_o x_t + U_o h_{t-1} + b_o) \\)  \n",
            "  ■ \\( c_t = f_t \\odot c_{t-1} + i_t \\odot \\tanh(W_c x_t + U_c h_{t-1} + b_c) \\)  \n",
            "  ■ \\( h_t = o_t \\odot \\tanh(c_t) \\)  \n",
            "  Where \\( \\sigma \\) is the sigmoid function, \\( \\tanh \\) is the hyperbolic tangent function, and \\( \\odot \\) denotes element-wise multiplication.  \n",
            "- **Core Algorithms/Procedures**:  \n",
            "  - Forward propagation computes the hidden and cell states.  \n",
            "  - Backpropagation through time (BPTT) is used for training, computing gradients of the loss with respect to the model parameters.\n",
            "\n",
            "## 3. **Working Mechanism**\n",
            "- **Step-by-Step Operational Flow**:  \n",
            "  1. **Input Processing**: The input \\( x_t \\) is processed along with the previous hidden state \\( h_{t-1} \\) to compute the gates.  \n",
            "  2. **Gate Computations**: The forget, input, and output gates are computed using sigmoid and tanh functions.  \n",
            "  3. **Cell State Update**: The cell state \\( c_t \\) is updated based on the forget gate and the input gate.  \n",
            "  4. **Output Generation**: The hidden state \\( h_t \\) is computed using the output gate and the cell state.  \n",
            "- **Critical Processes and Transformations**:  \n",
            "  - The forget gate determines how much of the previous cell state to retain.  \n",
            "  - The input gate controls the addition of new information to the cell state.  \n",
            "  - The output gate determines how much of the cell state is used to compute the output.  \n",
            "- **Resource Management**:  \n",
            "  - LSTMs require careful management of memory and computational resources, especially for long sequences.  \n",
            "- **Exception Handling**:  \n",
            "  - Techniques like gradient clipping are used to prevent exploding gradients during backpropagation.\n",
            "\n",
            "## 4. **Implementation Example**\n",
            "- **Use Case Scenario**:  \n",
            "  Implementing an LSTM for a simple text classification task, such as sentiment analysis.  \n",
            "- **Code Implementation or Technical Design**:  \n",
            "  ```python\n",
            "  import torch\n",
            "  import torch.nn as nn\n",
            "  import torch.optim as optim\n",
            "\n",
            "  class LSTMClassifier(nn.Module):\n",
            "      def __init__(self, input_dim, hidden_dim, output_dim):\n",
            "          super(LSTMClassifier, self).__init__()\n",
            "          self.hidden_dim = hidden_dim\n",
            "          self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
            "          self.fc = nn.Linear(hidden_dim, output_dim)\n",
            "\n",
            "      def forward(self, x):\n",
            "          # x shape: (batch_size, seq_len, input_dim)\n",
            "          lstm_out, _ = self.lstm(x)\n",
            "          # Get the last time step's output\n",
            "          lstm_out = lstm_out[:, -1, :]\n",
            "          return self.fc(lstm_out)\n",
            "\n",
            "  # Initialize the model, loss function, and optimizer\n",
            "  model = LSTMClassifier(input_dim=100, hidden_dim=128, output_dim=2)\n",
            "  criterion = nn.CrossEntropyLoss()\n",
            "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
            "  ```\n",
            "- **Step-by-Step Execution**:  \n",
            "  1. **Model Initialization**: Define the LSTM classifier with the desired input, hidden, and output dimensions.  \n",
            "  2. **Forward Pass**: Pass the input through the LSTM layer and then through the fully connected layer to get the output.  \n",
            "  3. **Loss Calculation**: Compute the loss using the cross-entropy loss function.  \n",
            "  4. **Backward Pass and Optimization**: Compute gradients and update the model parameters using the Adam optimizer.  \n",
            "- **Output Analysis**:  \n",
            "  The output is a probability distribution over the classes, which can be used to predict the sentiment of the input text.\n",
            "\n",
            "## 5. **Best Practices**\n",
            "- **Design Considerations**:  \n",
            "  - Choose the appropriate number of layers and hidden units based on the complexity of the task.  \n",
            "  - Use bidirectional LSTMs to capture both forward and backward dependencies in the sequence.  \n",
            "- **Optimization Techniques**:  \n",
            "  - Use gradient clipping to prevent exploding gradients.  \n",
            "  - Apply dropout to regularize the model and prevent overfitting.  \n",
            "- **Common Pitfalls**:  \n",
            "  - Vanishing or exploding gradients during backpropagation.  \n",
            "  - Overfitting due to insufficient regularization.  \n",
            "- **Performance Implications**:  \n",
            "  - LSTMs are computationally expensive for very long sequences due to their sequential processing nature.  \n",
            "\n",
            "## 6. **Applications**\n",
            "- **Real-World Use Cases**:  \n",
            "  - Language modeling and text generation.  \n",
            "  - Speech recognition and machine translation.  \n",
            "  - Time-series prediction and anomaly detection.  \n",
            "- **Industry Applications**:  \n",
            "  - Natural Language Processing (NLP) tasks in tech companies.  \n",
            "  - Financial forecasting and stock market analysis.  \n",
            "- **Integration Patterns**:  \n",
            "  - LSTMs can be integrated with convolutional neural networks (CNNs) for tasks like image captioning.  \n",
            "  - They can also be used in encoder-decoder architectures for sequence-to-sequence tasks.  \n",
            "- **Variations and Alternatives**:  \n",
            "  - Bidirectional LSTMs (BiLSTMs) for capturing bidirectional dependencies.  \n",
            "  - Gated Recurrent Units (GRUs) as a simpler alternative to LSTMs.  \n",
            "\n",
            "## 7. **Evaluation**\n",
            "- **Performance Metrics**:  \n",
            "  - Accuracy, precision, recall, and F1-score for classification tasks.  \n",
            "  - Mean Squared Error (MSE) or Mean Absolute Error (MAE) for regression tasks.  \n",
            "  - Perplexity for language modeling tasks.  \n",
            "- **Testing Approaches**:  \n",
            "  - Use cross-validation to evaluate the model's performance on unseen data.  \n",
            "  - Monitor overfitting by comparing training and validation metrics.  \n",
            "- **Debugging Strategies**:  \n",
            "  - Check for vanishing or exploding gradients during training.  \n",
            "  - Ensure that the model is sufficiently complex to capture the underlying patterns in the data.  \n",
            "- **Optimization Opportunities**:  \n",
            "  - Use pre-trained models and fine-tune them on specific tasks.  \n",
            "  - Experiment with different hyperparameters and architectures.  \n",
            "\n",
            "## 8. **Practice Problems**\n",
            "- **Concept Verification Questions**:  \n",
            "  1. What is the primary purpose of the forget gate in an LSTM?  \n",
            "     **Answer**: The forget gate determines what information to discard from the previous hidden state.  \n",
            "  2. How does the cell state in an LSTM help in capturing long-term dependencies?  \n",
            "     **Answer**: The cell state acts as a memory unit that can retain information for long sequences, controlled by the gates.  \n",
            "- **Implementation Challenges**:  \n",
            "  - Implement an LSTM from scratch without using any deep learning libraries.  \n",
            "  - Optimize an LSTM model for a specific task, such as reducing the number of parameters while maintaining performance.  \n",
            "- **Problem-Solving Scenarios**:  \n",
            "  - Debugging an LSTM model that is not learning properly.  \n",
            "  - Handling imbalanced datasets in LSTM-based classification tasks.  \n",
            "- **Solutions with Explanations**:  \n",
            "  - For debugging, check for issues like insufficient training data, incorrect hyperparameters, or vanishing gradients.  \n",
            "  - For imbalanced datasets, use techniques like oversampling the minority class, undersampling the majority class, or adjusting the class weights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_answer(text):\n",
        "   \"\"\"Extract the answer, removing everything before 'Show output examples where applicable'\"\"\"\n",
        "   # Find the index of the end section\n",
        "   start_index = text.find(\"</think>\")\n",
        "\n",
        "   if start_index == -1:\n",
        "       return text.strip()\n",
        "\n",
        "   return text[start_index + len(\"</think>\"):].strip()\n",
        "\n",
        "# Usage\n",
        "clean_answer = extract_answer(answer)\n",
        "print(clean_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WAWYAuWl9SCR",
        "outputId": "f58865e2-6b47-47c3-f45d-affb7224baad"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## 1. **Concept Overview**\n",
            "- **Core Definition and Purpose**:  \n",
            "  Long Short-Term Memory (LSTM) networks are a type of Recurrent Neural Network (RNN) designed to handle the vanishing gradient problem in traditional RNNs. They are primarily used for sequence modeling tasks, such as language modeling, speech recognition, and time-series prediction.  \n",
            "- **Key Principles**:  \n",
            "  - LSTMs introduce memory cells and gates (input, output, and forget gates) to control the flow of information.  \n",
            "  - These components allow the network to learn long-term dependencies by selectively retaining or discarding information.  \n",
            "- **Relationship to Broader Computing Concepts**:  \n",
            "  - LSTMs are a part of deep learning and neural networks, extending the capabilities of RNNs.  \n",
            "  - They are particularly useful for sequential data, where temporal relationships are important.\n",
            "\n",
            "## 2. **Technical Components**\n",
            "- **Primary Elements and Their Roles**:  \n",
            "  - **Memory Cell (Cell State)**: Acts as the internal memory of the LSTM, storing information over long sequences.  \n",
            "  - **Input Gate**: Controls the flow of new information into the memory cell.  \n",
            "  - **Output Gate**: Controls the output based on the memory cell and the hidden state.  \n",
            "  - **Forget Gate**: Determines what information to discard from the previous hidden state.  \n",
            "- **Relationships and Interactions**:  \n",
            "  - The gates interact to regulate the memory cell's state, ensuring that only relevant information is retained or updated.  \n",
            "- **Implementation Details**:  \n",
            "  - The LSTM architecture consists of multiple layers, with each layer containing memory cells and gates.  \n",
            "- **Mathematical Equations**:  \n",
            "  Let \\( f_t \\), \\( i_t \\), and \\( o_t \\) represent the forget, input, and output gates, respectively. Let \\( c_t \\) and \\( h_t \\) denote the cell state and hidden state at time \\( t \\). The key equations are:  \n",
            "  ■ \\( f_t = \\sigma(W_f x_t + U_f h_{t-1} + b_f) \\)  \n",
            "  ■ \\( i_t = \\sigma(W_i x_t + U_i h_{t-1} + b_i) \\)  \n",
            "  ■ \\( o_t = \\sigma(W_o x_t + U_o h_{t-1} + b_o) \\)  \n",
            "  ■ \\( c_t = f_t \\odot c_{t-1} + i_t \\odot \\tanh(W_c x_t + U_c h_{t-1} + b_c) \\)  \n",
            "  ■ \\( h_t = o_t \\odot \\tanh(c_t) \\)  \n",
            "  Where \\( \\sigma \\) is the sigmoid function, \\( \\tanh \\) is the hyperbolic tangent function, and \\( \\odot \\) denotes element-wise multiplication.  \n",
            "- **Core Algorithms/Procedures**:  \n",
            "  - Forward propagation computes the hidden and cell states.  \n",
            "  - Backpropagation through time (BPTT) is used for training, computing gradients of the loss with respect to the model parameters.\n",
            "\n",
            "## 3. **Working Mechanism**\n",
            "- **Step-by-Step Operational Flow**:  \n",
            "  1. **Input Processing**: The input \\( x_t \\) is processed along with the previous hidden state \\( h_{t-1} \\) to compute the gates.  \n",
            "  2. **Gate Computations**: The forget, input, and output gates are computed using sigmoid and tanh functions.  \n",
            "  3. **Cell State Update**: The cell state \\( c_t \\) is updated based on the forget gate and the input gate.  \n",
            "  4. **Output Generation**: The hidden state \\( h_t \\) is computed using the output gate and the cell state.  \n",
            "- **Critical Processes and Transformations**:  \n",
            "  - The forget gate determines how much of the previous cell state to retain.  \n",
            "  - The input gate controls the addition of new information to the cell state.  \n",
            "  - The output gate determines how much of the cell state is used to compute the output.  \n",
            "- **Resource Management**:  \n",
            "  - LSTMs require careful management of memory and computational resources, especially for long sequences.  \n",
            "- **Exception Handling**:  \n",
            "  - Techniques like gradient clipping are used to prevent exploding gradients during backpropagation.\n",
            "\n",
            "## 4. **Implementation Example**\n",
            "- **Use Case Scenario**:  \n",
            "  Implementing an LSTM for a simple text classification task, such as sentiment analysis.  \n",
            "- **Code Implementation or Technical Design**:  \n",
            "  ```python\n",
            "  import torch\n",
            "  import torch.nn as nn\n",
            "  import torch.optim as optim\n",
            "\n",
            "  class LSTMClassifier(nn.Module):\n",
            "      def __init__(self, input_dim, hidden_dim, output_dim):\n",
            "          super(LSTMClassifier, self).__init__()\n",
            "          self.hidden_dim = hidden_dim\n",
            "          self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
            "          self.fc = nn.Linear(hidden_dim, output_dim)\n",
            "\n",
            "      def forward(self, x):\n",
            "          # x shape: (batch_size, seq_len, input_dim)\n",
            "          lstm_out, _ = self.lstm(x)\n",
            "          # Get the last time step's output\n",
            "          lstm_out = lstm_out[:, -1, :]\n",
            "          return self.fc(lstm_out)\n",
            "\n",
            "  # Initialize the model, loss function, and optimizer\n",
            "  model = LSTMClassifier(input_dim=100, hidden_dim=128, output_dim=2)\n",
            "  criterion = nn.CrossEntropyLoss()\n",
            "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
            "  ```\n",
            "- **Step-by-Step Execution**:  \n",
            "  1. **Model Initialization**: Define the LSTM classifier with the desired input, hidden, and output dimensions.  \n",
            "  2. **Forward Pass**: Pass the input through the LSTM layer and then through the fully connected layer to get the output.  \n",
            "  3. **Loss Calculation**: Compute the loss using the cross-entropy loss function.  \n",
            "  4. **Backward Pass and Optimization**: Compute gradients and update the model parameters using the Adam optimizer.  \n",
            "- **Output Analysis**:  \n",
            "  The output is a probability distribution over the classes, which can be used to predict the sentiment of the input text.\n",
            "\n",
            "## 5. **Best Practices**\n",
            "- **Design Considerations**:  \n",
            "  - Choose the appropriate number of layers and hidden units based on the complexity of the task.  \n",
            "  - Use bidirectional LSTMs to capture both forward and backward dependencies in the sequence.  \n",
            "- **Optimization Techniques**:  \n",
            "  - Use gradient clipping to prevent exploding gradients.  \n",
            "  - Apply dropout to regularize the model and prevent overfitting.  \n",
            "- **Common Pitfalls**:  \n",
            "  - Vanishing or exploding gradients during backpropagation.  \n",
            "  - Overfitting due to insufficient regularization.  \n",
            "- **Performance Implications**:  \n",
            "  - LSTMs are computationally expensive for very long sequences due to their sequential processing nature.  \n",
            "\n",
            "## 6. **Applications**\n",
            "- **Real-World Use Cases**:  \n",
            "  - Language modeling and text generation.  \n",
            "  - Speech recognition and machine translation.  \n",
            "  - Time-series prediction and anomaly detection.  \n",
            "- **Industry Applications**:  \n",
            "  - Natural Language Processing (NLP) tasks in tech companies.  \n",
            "  - Financial forecasting and stock market analysis.  \n",
            "- **Integration Patterns**:  \n",
            "  - LSTMs can be integrated with convolutional neural networks (CNNs) for tasks like image captioning.  \n",
            "  - They can also be used in encoder-decoder architectures for sequence-to-sequence tasks.  \n",
            "- **Variations and Alternatives**:  \n",
            "  - Bidirectional LSTMs (BiLSTMs) for capturing bidirectional dependencies.  \n",
            "  - Gated Recurrent Units (GRUs) as a simpler alternative to LSTMs.  \n",
            "\n",
            "## 7. **Evaluation**\n",
            "- **Performance Metrics**:  \n",
            "  - Accuracy, precision, recall, and F1-score for classification tasks.  \n",
            "  - Mean Squared Error (MSE) or Mean Absolute Error (MAE) for regression tasks.  \n",
            "  - Perplexity for language modeling tasks.  \n",
            "- **Testing Approaches**:  \n",
            "  - Use cross-validation to evaluate the model's performance on unseen data.  \n",
            "  - Monitor overfitting by comparing training and validation metrics.  \n",
            "- **Debugging Strategies**:  \n",
            "  - Check for vanishing or exploding gradients during training.  \n",
            "  - Ensure that the model is sufficiently complex to capture the underlying patterns in the data.  \n",
            "- **Optimization Opportunities**:  \n",
            "  - Use pre-trained models and fine-tune them on specific tasks.  \n",
            "  - Experiment with different hyperparameters and architectures.  \n",
            "\n",
            "## 8. **Practice Problems**\n",
            "- **Concept Verification Questions**:  \n",
            "  1. What is the primary purpose of the forget gate in an LSTM?  \n",
            "     **Answer**: The forget gate determines what information to discard from the previous hidden state.  \n",
            "  2. How does the cell state in an LSTM help in capturing long-term dependencies?  \n",
            "     **Answer**: The cell state acts as a memory unit that can retain information for long sequences, controlled by the gates.  \n",
            "- **Implementation Challenges**:  \n",
            "  - Implement an LSTM from scratch without using any deep learning libraries.  \n",
            "  - Optimize an LSTM model for a specific task, such as reducing the number of parameters while maintaining performance.  \n",
            "- **Problem-Solving Scenarios**:  \n",
            "  - Debugging an LSTM model that is not learning properly.  \n",
            "  - Handling imbalanced datasets in LSTM-based classification tasks.  \n",
            "- **Solutions with Explanations**:  \n",
            "  - For debugging, check for issues like insufficient training data, incorrect hyperparameters, or vanishing gradients.  \n",
            "  - For imbalanced datasets, use techniques like oversampling the minority class, undersampling the majority class, or adjusting the class weights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Format the content"
      ],
      "metadata": {
        "id": "qhsE3UTC-n0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def format_text(text):\n",
        "    \"\"\"\n",
        "    Format text with improved numbering system and removal of empty items\n",
        "    \"\"\"\n",
        "    lines = text.split('\\n')\n",
        "    formatted_lines = []\n",
        "    level_counters = {}\n",
        "    current_section_level = 0\n",
        "\n",
        "    def get_indentation(line):\n",
        "        return len(line) - len(line.lstrip())\n",
        "\n",
        "    def clean_content(content):\n",
        "        \"\"\"Remove dashes and clean up content\"\"\"\n",
        "        # Remove standalone dashes\n",
        "        content = re.sub(r'^--+$', '', content)\n",
        "        # Remove dashes with spaces around them\n",
        "        content = re.sub(r'\\s*--+\\s*', ' ', content)\n",
        "        # Clean up extra spaces\n",
        "        content = re.sub(r'\\s+', ' ', content)\n",
        "        return content.strip()\n",
        "\n",
        "    def process_numbered_item(line):\n",
        "        \"\"\"Process numbered items and return None if empty after cleaning\"\"\"\n",
        "        # Match numbered items with or without bold markers\n",
        "        match = re.match(r'^(\\d+\\.\\s*)((?:\\*\\*)?[^:]*(?:\\*\\*)?:?\\s*)?(.*)$', line.strip())\n",
        "        if match:\n",
        "            number, title, content = match.groups()\n",
        "            title = title or ''\n",
        "            content = content or ''\n",
        "\n",
        "            # Clean the content\n",
        "            cleaned_content = clean_content(content)\n",
        "            cleaned_title = title.strip()\n",
        "\n",
        "            # If both title and content are empty (or just dashes), return None\n",
        "            if not cleaned_title and not cleaned_content:\n",
        "                return None\n",
        "\n",
        "            # Reconstruct the line\n",
        "            return f\"{number}{title}{cleaned_content}\".rstrip()\n",
        "        return line\n",
        "\n",
        "    for i, line in enumerate(lines):\n",
        "        if not line.strip():\n",
        "            formatted_lines.append(line)\n",
        "            continue\n",
        "\n",
        "        indent = get_indentation(line)\n",
        "        stripped_line = line.strip()\n",
        "\n",
        "        # Convert single asterisks to double\n",
        "        line = re.sub(\n",
        "            r'(?<![\\*])\\*(?![\\*])([^\\*]+)(?<![\\*])\\*(?![\\*])',\n",
        "            r'**\\1**',\n",
        "            line\n",
        "        )\n",
        "\n",
        "        # Handle section headers\n",
        "        if stripped_line.startswith('##'):\n",
        "            level_counters.clear()\n",
        "            current_section_level = indent\n",
        "            heading_parts = stripped_line.split(' ', 1)\n",
        "            if len(heading_parts) > 1:\n",
        "                line = f\"{' ' * indent}{heading_parts[0]} {clean_content(heading_parts[1])}\"\n",
        "            formatted_lines.append(line)\n",
        "\n",
        "        # Handle numbered items\n",
        "        elif re.match(r'^\\d+\\.', stripped_line):\n",
        "            spaces = ' ' * indent\n",
        "            processed_line = process_numbered_item(stripped_line)\n",
        "            if processed_line is not None:  # Only add if there's actual content\n",
        "                line = f\"{spaces}{processed_line}\"\n",
        "                formatted_lines.append(line)\n",
        "\n",
        "        # Handle other bullet points (###, ####, •, -, ■)\n",
        "        elif any(stripped_line.startswith(marker) for marker in ('###', '####', '•', '-', '■')):\n",
        "            if indent not in level_counters:\n",
        "                level_counters[indent] = 1\n",
        "            else:\n",
        "                level_counters[indent] += 1\n",
        "\n",
        "            level_counters = {k: v for k, v in level_counters.items() if k <= indent}\n",
        "            number = level_counters[indent]\n",
        "            spaces = ' ' * indent\n",
        "\n",
        "            # Extract content based on marker type\n",
        "            if stripped_line.startswith('####'):\n",
        "                content = stripped_line[4:]\n",
        "            elif stripped_line.startswith('###'):\n",
        "                content = stripped_line[3:]\n",
        "            else:\n",
        "                content = stripped_line[1:]\n",
        "\n",
        "            content = clean_content(content.strip())\n",
        "            if content:  # Only add if there's content\n",
        "                line = f\"{spaces}{number}. {content}\"\n",
        "                formatted_lines.append(line)\n",
        "\n",
        "        else:\n",
        "            # Regular text lines\n",
        "            current_section_level = indent\n",
        "            cleaned_line = clean_content(stripped_line)\n",
        "            if cleaned_line:  # Only add if there's content\n",
        "                line = f\"{' ' * indent}{cleaned_line}\"\n",
        "                formatted_lines.append(line)\n",
        "\n",
        "    # Clean up consecutive empty lines\n",
        "    cleaned_lines = []\n",
        "    prev_empty = False\n",
        "    for line in formatted_lines:\n",
        "        if not line.strip():\n",
        "            if not prev_empty:\n",
        "                cleaned_lines.append(line)\n",
        "            prev_empty = True\n",
        "        else:\n",
        "            cleaned_lines.append(line)\n",
        "            prev_empty = False\n",
        "\n",
        "    return '\\n'.join(cleaned_lines)\n",
        "\n",
        "def process_file(input_text):\n",
        "    \"\"\"Process the entire file and apply formatting\"\"\"\n",
        "    return format_text(input_text)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    result = process_file(clean_answer)\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AiMfivHK-hz2",
        "outputId": "fc5dcc5e-fb0c-47d7-97a6-82de7ef4f149"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## 1. **Concept Overview**\n",
            "1. **Core Definition and Purpose**:\n",
            "  Long Short-Term Memory (LSTM) networks are a type of Recurrent Neural Network (RNN) designed to handle the vanishing gradient problem in traditional RNNs. They are primarily used for sequence modeling tasks, such as language modeling, speech recognition, and time-series prediction.\n",
            "2. **Key Principles**:\n",
            "  1. LSTMs introduce memory cells and gates (input, output, and forget gates) to control the flow of information.\n",
            "  2. These components allow the network to learn long-term dependencies by selectively retaining or discarding information.\n",
            "3. **Relationship to Broader Computing Concepts**:\n",
            "  1. LSTMs are a part of deep learning and neural networks, extending the capabilities of RNNs.\n",
            "  2. They are particularly useful for sequential data, where temporal relationships are important.\n",
            "\n",
            "## 2. **Technical Components**\n",
            "1. **Primary Elements and Their Roles**:\n",
            "  1. **Memory Cell (Cell State)**: Acts as the internal memory of the LSTM, storing information over long sequences.\n",
            "  2. **Input Gate**: Controls the flow of new information into the memory cell.\n",
            "  3. **Output Gate**: Controls the output based on the memory cell and the hidden state.\n",
            "  4. **Forget Gate**: Determines what information to discard from the previous hidden state.\n",
            "2. **Relationships and Interactions**:\n",
            "  1. The gates interact to regulate the memory cell's state, ensuring that only relevant information is retained or updated.\n",
            "3. **Implementation Details**:\n",
            "  1. The LSTM architecture consists of multiple layers, with each layer containing memory cells and gates.\n",
            "4. **Mathematical Equations**:\n",
            "  Let \\( f_t \\), \\( i_t \\), and \\( o_t \\) represent the forget, input, and output gates, respectively. Let \\( c_t \\) and \\( h_t \\) denote the cell state and hidden state at time \\( t \\). The key equations are:\n",
            "  1. \\( f_t = \\sigma(W_f x_t + U_f h_{t-1} + b_f) \\)\n",
            "  2. \\( i_t = \\sigma(W_i x_t + U_i h_{t-1} + b_i) \\)\n",
            "  3. \\( o_t = \\sigma(W_o x_t + U_o h_{t-1} + b_o) \\)\n",
            "  4. \\( c_t = f_t \\odot c_{t-1} + i_t \\odot \\tanh(W_c x_t + U_c h_{t-1} + b_c) \\)\n",
            "  5. \\( h_t = o_t \\odot \\tanh(c_t) \\)\n",
            "  Where \\( \\sigma \\) is the sigmoid function, \\( \\tanh \\) is the hyperbolic tangent function, and \\( \\odot \\) denotes element-wise multiplication.\n",
            "5. **Core Algorithms/Procedures**:\n",
            "  1. Forward propagation computes the hidden and cell states.\n",
            "  2. Backpropagation through time (BPTT) is used for training, computing gradients of the loss with respect to the model parameters.\n",
            "\n",
            "## 3. **Working Mechanism**\n",
            "1. **Step-by-Step Operational Flow**:\n",
            "  1. **Input Processing**: The input \\( x_t \\) is processed along with the previous hidden state \\( h_{t-1} \\) to compute the gates.\n",
            "  2. **Gate Computations**: The forget, input, and output gates are computed using sigmoid and tanh functions.\n",
            "  3. **Cell State Update**: The cell state \\( c_t \\) is updated based on the forget gate and the input gate.\n",
            "  4. **Output Generation**: The hidden state \\( h_t \\) is computed using the output gate and the cell state.\n",
            "2. **Critical Processes and Transformations**:\n",
            "  1. The forget gate determines how much of the previous cell state to retain.\n",
            "  2. The input gate controls the addition of new information to the cell state.\n",
            "  3. The output gate determines how much of the cell state is used to compute the output.\n",
            "3. **Resource Management**:\n",
            "  1. LSTMs require careful management of memory and computational resources, especially for long sequences.\n",
            "4. **Exception Handling**:\n",
            "  1. Techniques like gradient clipping are used to prevent exploding gradients during backpropagation.\n",
            "\n",
            "## 4. **Implementation Example**\n",
            "1. **Use Case Scenario**:\n",
            "  Implementing an LSTM for a simple text classification task, such as sentiment analysis.\n",
            "2. **Code Implementation or Technical Design**:\n",
            "  ```python\n",
            "  import torch\n",
            "  import torch.nn as nn\n",
            "  import torch.optim as optim\n",
            "\n",
            "  class LSTMClassifier(nn.Module):\n",
            "      def __init__(self, input_dim, hidden_dim, output_dim):\n",
            "          super(LSTMClassifier, self).__init__()\n",
            "          self.hidden_dim = hidden_dim\n",
            "          self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
            "          self.fc = nn.Linear(hidden_dim, output_dim)\n",
            "\n",
            "      def forward(self, x):\n",
            "          # x shape: (batch_size, seq_len, input_dim)\n",
            "          lstm_out, _ = self.lstm(x)\n",
            "          # Get the last time step's output\n",
            "          lstm_out = lstm_out[:, -1, :]\n",
            "          return self.fc(lstm_out)\n",
            "\n",
            "  # Initialize the model, loss function, and optimizer\n",
            "  model = LSTMClassifier(input_dim=100, hidden_dim=128, output_dim=2)\n",
            "  criterion = nn.CrossEntropyLoss()\n",
            "  optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
            "  ```\n",
            "3. **Step-by-Step Execution**:\n",
            "  1. **Model Initialization**: Define the LSTM classifier with the desired input, hidden, and output dimensions.\n",
            "  2. **Forward Pass**: Pass the input through the LSTM layer and then through the fully connected layer to get the output.\n",
            "  3. **Loss Calculation**: Compute the loss using the cross-entropy loss function.\n",
            "  4. **Backward Pass and Optimization**: Compute gradients and update the model parameters using the Adam optimizer.\n",
            "4. **Output Analysis**:\n",
            "  The output is a probability distribution over the classes, which can be used to predict the sentiment of the input text.\n",
            "\n",
            "## 5. **Best Practices**\n",
            "1. **Design Considerations**:\n",
            "  1. Choose the appropriate number of layers and hidden units based on the complexity of the task.\n",
            "  2. Use bidirectional LSTMs to capture both forward and backward dependencies in the sequence.\n",
            "2. **Optimization Techniques**:\n",
            "  1. Use gradient clipping to prevent exploding gradients.\n",
            "  2. Apply dropout to regularize the model and prevent overfitting.\n",
            "3. **Common Pitfalls**:\n",
            "  1. Vanishing or exploding gradients during backpropagation.\n",
            "  2. Overfitting due to insufficient regularization.\n",
            "4. **Performance Implications**:\n",
            "  1. LSTMs are computationally expensive for very long sequences due to their sequential processing nature.\n",
            "\n",
            "## 6. **Applications**\n",
            "1. **Real-World Use Cases**:\n",
            "  1. Language modeling and text generation.\n",
            "  2. Speech recognition and machine translation.\n",
            "  3. Time-series prediction and anomaly detection.\n",
            "2. **Industry Applications**:\n",
            "  1. Natural Language Processing (NLP) tasks in tech companies.\n",
            "  2. Financial forecasting and stock market analysis.\n",
            "3. **Integration Patterns**:\n",
            "  1. LSTMs can be integrated with convolutional neural networks (CNNs) for tasks like image captioning.\n",
            "  2. They can also be used in encoder-decoder architectures for sequence-to-sequence tasks.\n",
            "4. **Variations and Alternatives**:\n",
            "  1. Bidirectional LSTMs (BiLSTMs) for capturing bidirectional dependencies.\n",
            "  2. Gated Recurrent Units (GRUs) as a simpler alternative to LSTMs.\n",
            "\n",
            "## 7. **Evaluation**\n",
            "1. **Performance Metrics**:\n",
            "  1. Accuracy, precision, recall, and F1-score for classification tasks.\n",
            "  2. Mean Squared Error (MSE) or Mean Absolute Error (MAE) for regression tasks.\n",
            "  3. Perplexity for language modeling tasks.\n",
            "2. **Testing Approaches**:\n",
            "  1. Use cross-validation to evaluate the model's performance on unseen data.\n",
            "  2. Monitor overfitting by comparing training and validation metrics.\n",
            "3. **Debugging Strategies**:\n",
            "  1. Check for vanishing or exploding gradients during training.\n",
            "  2. Ensure that the model is sufficiently complex to capture the underlying patterns in the data.\n",
            "4. **Optimization Opportunities**:\n",
            "  1. Use pre-trained models and fine-tune them on specific tasks.\n",
            "  2. Experiment with different hyperparameters and architectures.\n",
            "\n",
            "## 8. **Practice Problems**\n",
            "1. **Concept Verification Questions**:\n",
            "  1. What is the primary purpose of the forget gate in an LSTM?\n",
            "     **Answer**: The forget gate determines what information to discard from the previous hidden state.\n",
            "  2. How does the cell state in an LSTM help in capturing long-term dependencies?\n",
            "     **Answer**: The cell state acts as a memory unit that can retain information for long sequences, controlled by the gates.\n",
            "2. **Implementation Challenges**:\n",
            "  1. Implement an LSTM from scratch without using any deep learning libraries.\n",
            "  2. Optimize an LSTM model for a specific task, such as reducing the number of parameters while maintaining performance.\n",
            "3. **Problem-Solving Scenarios**:\n",
            "  1. Debugging an LSTM model that is not learning properly.\n",
            "  2. Handling imbalanced datasets in LSTM-based classification tasks.\n",
            "4. **Solutions with Explanations**:\n",
            "  1. For debugging, check for issues like insufficient training data, incorrect hyperparameters, or vanishing gradients.\n",
            "  2. For imbalanced datasets, use techniques like oversampling the minority class, undersampling the majority class, or adjusting the class weights.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save Content in txt File"
      ],
      "metadata": {
        "id": "llB7Yp2bD4vR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"content.txt\"\n",
        "with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(result)"
      ],
      "metadata": {
        "id": "AjSODvTHD8uZ"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Formatted Content to Json"
      ],
      "metadata": {
        "id": "VojAbxMyYuyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "class MarkdownToJsonConverter:\n",
        "    def __init__(self):\n",
        "        self.result = {}\n",
        "        self.current_section = None\n",
        "        self.current_item = None\n",
        "        self.current_subitem = None\n",
        "        self.in_code_block = False\n",
        "        self.code_content = []\n",
        "        self.code_language = None\n",
        "        self.indentation_level = 0\n",
        "        self.last_item_at_level = {}  # Track last item at each indentation level\n",
        "\n",
        "    def get_indentation_level(self, line):\n",
        "        \"\"\"Calculate the indentation level of a line\"\"\"\n",
        "        return len(line) - len(line.lstrip())\n",
        "\n",
        "    def parse_section(self, line):\n",
        "        \"\"\"Parse a section header line\"\"\"\n",
        "        if self.in_code_block:\n",
        "            return False\n",
        "\n",
        "        # Match section headers with more flexible format\n",
        "        section_match = re.match(r'^##\\s*(\\d+)\\.\\s*(?:\\*\\*)?([^*]+?)(?:\\*\\*)?$', line.strip())\n",
        "\n",
        "        if section_match:\n",
        "            section_num = section_match.group(1)\n",
        "            section_title = section_match.group(2).strip()\n",
        "            self.current_section = {\n",
        "                \"type\": \"section\",\n",
        "                \"number\": section_num,\n",
        "                \"title\": section_title,\n",
        "                \"items\": []\n",
        "            }\n",
        "            self.result[f\"Section {section_num}\"] = self.current_section\n",
        "            self.current_item = None\n",
        "            self.current_subitem = None\n",
        "            self.last_item_at_level = {}  # Reset item tracking for new section\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def find_parent_item(self, indentation):\n",
        "        \"\"\"Find the appropriate parent item based on indentation\"\"\"\n",
        "        for level in sorted(self.last_item_at_level.keys(), reverse=True):\n",
        "            if level < indentation:\n",
        "                return self.last_item_at_level[level]\n",
        "        return None\n",
        "\n",
        "    def parse_item(self, line):\n",
        "        \"\"\"Parse a numbered item line with improved title and nested content handling\"\"\"\n",
        "        if self.in_code_block:\n",
        "            return False\n",
        "\n",
        "        stripped_line = line.lstrip()\n",
        "        indentation = self.get_indentation_level(line)\n",
        "\n",
        "        # Handle both numbered items and titled content\n",
        "        item_match = re.match(r'^(\\d+)\\.\\s*(?:\\*\\*([^*]+?)\\*\\*:?)?\\s*(.+)?$', stripped_line)\n",
        "        title_match = re.match(r'^\\*\\*([^*]+?)\\*\\*:?\\s*(.+)?$', stripped_line)\n",
        "\n",
        "        if item_match:\n",
        "            item_num = item_match.group(1)\n",
        "            item_title = item_match.group(2)\n",
        "            item_content = item_match.group(3)\n",
        "\n",
        "            new_item = {\n",
        "                \"type\": \"item\",\n",
        "                \"number\": item_num,\n",
        "                \"indentation\": indentation,\n",
        "                \"content\": []\n",
        "            }\n",
        "\n",
        "            if item_title:\n",
        "                new_item[\"title\"] = item_title.strip()\n",
        "\n",
        "            if item_content:\n",
        "                new_item[\"content\"].append({\n",
        "                    \"type\": \"text\",\n",
        "                    \"content\": item_content.strip()\n",
        "                })\n",
        "\n",
        "            parent_item = self.find_parent_item(indentation)\n",
        "\n",
        "            if parent_item:\n",
        "                if \"subitems\" not in parent_item:\n",
        "                    parent_item[\"subitems\"] = []\n",
        "                parent_item[\"subitems\"].append(new_item)\n",
        "                self.current_subitem = new_item\n",
        "            else:\n",
        "                if self.current_section:\n",
        "                    self.current_section[\"items\"].append(new_item)\n",
        "                self.current_item = new_item\n",
        "                self.current_subitem = None\n",
        "\n",
        "            self.last_item_at_level[indentation] = new_item\n",
        "            return True\n",
        "\n",
        "        elif title_match:\n",
        "            title = title_match.group(1).strip()\n",
        "            content = title_match.group(2)\n",
        "\n",
        "            new_item = {\n",
        "                \"type\": \"item\",\n",
        "                \"title\": title,\n",
        "                \"indentation\": indentation,\n",
        "                \"content\": []\n",
        "            }\n",
        "\n",
        "            if content:\n",
        "                new_item[\"content\"].append({\n",
        "                    \"type\": \"text\",\n",
        "                    \"content\": content.strip()\n",
        "                })\n",
        "\n",
        "            parent_item = self.find_parent_item(indentation)\n",
        "\n",
        "            if parent_item:\n",
        "                if \"subitems\" not in parent_item:\n",
        "                    parent_item[\"subitems\"] = []\n",
        "                parent_item[\"subitems\"].append(new_item)\n",
        "                self.current_subitem = new_item\n",
        "            else:\n",
        "                if self.current_section:\n",
        "                    self.current_section[\"items\"].append(new_item)\n",
        "                self.current_item = new_item\n",
        "\n",
        "            self.last_item_at_level[indentation] = new_item\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def handle_code_block(self, line):\n",
        "        \"\"\"Handle code block markers and content with improved nesting support\"\"\"\n",
        "        stripped_line = line.lstrip()\n",
        "        indentation = self.get_indentation_level(line)\n",
        "\n",
        "        if stripped_line.startswith('```'):\n",
        "            if not self.in_code_block:\n",
        "                # Start of code block\n",
        "                self.in_code_block = True\n",
        "                self.code_language = stripped_line[3:].strip()\n",
        "                self.code_content = []\n",
        "                self.code_indentation = indentation\n",
        "            else:\n",
        "                # End of code block\n",
        "                target_item = self.find_parent_item(self.code_indentation)\n",
        "                if not target_item:\n",
        "                    target_item = self.current_item\n",
        "\n",
        "                if target_item and self.code_content:\n",
        "                    content = '\\n'.join(\n",
        "                        line[self.code_indentation:] if line.startswith(' ' * self.code_indentation)\n",
        "                        else line\n",
        "                        for line in self.code_content\n",
        "                    )\n",
        "                    target_item[\"content\"].append({\n",
        "                        \"type\": \"code\",\n",
        "                        \"language\": self.code_language or \"\",\n",
        "                        \"content\": content,\n",
        "                        \"indentation\": self.code_indentation\n",
        "                    })\n",
        "                self.in_code_block = False\n",
        "                self.code_content = []\n",
        "                self.code_language = None\n",
        "            return True\n",
        "\n",
        "        if self.in_code_block:\n",
        "            self.code_content.append(line)  # Store the line with original indentation\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def handle_text_content(self, line):\n",
        "        \"\"\"Handle regular text content with improved indentation awareness\"\"\"\n",
        "        if not self.in_code_block and line.strip():\n",
        "            indentation = self.get_indentation_level(line)\n",
        "            content = line.strip()\n",
        "\n",
        "            target_item = self.find_parent_item(indentation)\n",
        "            if not target_item:\n",
        "                target_item = self.current_item\n",
        "\n",
        "            if target_item and content:\n",
        "                target_item[\"content\"].append({\n",
        "                    \"type\": \"text\",\n",
        "                    \"content\": content,\n",
        "                    \"indentation\": indentation\n",
        "                })\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def convert(self, markdown_text):\n",
        "        \"\"\"Convert markdown text to JSON structure with improved handling of nested content\"\"\"\n",
        "        self.result = {}\n",
        "        self.last_item_at_level = {}\n",
        "        lines = markdown_text.split('\\n')\n",
        "\n",
        "        for line in lines:\n",
        "            # Skip empty lines outside of code blocks\n",
        "            if not self.in_code_block and not line.strip():\n",
        "                continue\n",
        "\n",
        "            # Handle code blocks first\n",
        "            if self.handle_code_block(line):\n",
        "                continue\n",
        "\n",
        "            # Try to parse as section\n",
        "            if self.parse_section(line):\n",
        "                continue\n",
        "\n",
        "            # Try to parse as item\n",
        "            if self.parse_item(line):\n",
        "                continue\n",
        "\n",
        "            # Handle remaining text content\n",
        "            self.handle_text_content(line)\n",
        "\n",
        "        # Clean up empty sections and items\n",
        "        for section_key, section in list(self.result.items()):\n",
        "            if not section[\"items\"]:\n",
        "                del self.result[section_key]\n",
        "                continue\n",
        "\n",
        "            # Clean up items recursively\n",
        "            self._clean_items(section[\"items\"])\n",
        "\n",
        "        return self.result\n",
        "\n",
        "    def _clean_items(self, items):\n",
        "        \"\"\"Recursively clean up empty content and subitems\"\"\"\n",
        "        for item in items:\n",
        "            if \"content\" in item and not item[\"content\"]:\n",
        "                del item[\"content\"]\n",
        "\n",
        "            if \"subitems\" in item:\n",
        "                self._clean_items(item[\"subitems\"])\n",
        "                if not item[\"subitems\"]:\n",
        "                    del item[\"subitems\"]\n",
        "\n",
        "            # Remove indentation from final output\n",
        "            if \"indentation\" in item:\n",
        "                del item[\"indentation\"]\n",
        "\n",
        "\n",
        "\n",
        "def convert_markdown_file(input_file, output_file):\n",
        "    try:\n",
        "        with open(input_file, 'r', encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        converter = MarkdownToJsonConverter()\n",
        "        json_output = converter.convert(content)\n",
        "\n",
        "        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(json_output, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        return json_output\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    result = convert_markdown_file(\"content.txt\", \"output.json\")\n",
        "\n",
        "    # Print first section as sample\n",
        "    if result:\n",
        "        first_section = next(iter(result.values()))\n",
        "        print(\"Sample output (first section):\")\n",
        "        print(json.dumps(first_section, indent=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9jrPn2-Y0hz",
        "outputId": "5afc9104-e8b5-44f6-925f-529767936d81"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample output (first section):\n",
            "{\n",
            "  \"type\": \"section\",\n",
            "  \"number\": \"1\",\n",
            "  \"title\": \"Concept Overview\",\n",
            "  \"items\": [\n",
            "    {\n",
            "      \"type\": \"item\",\n",
            "      \"number\": \"1\",\n",
            "      \"content\": [\n",
            "        {\n",
            "          \"type\": \"text\",\n",
            "          \"content\": \"Long Short-Term Memory (LSTM) networks are a type of Recurrent Neural Network (RNN) designed to handle the vanishing gradient problem in traditional RNNs. They are primarily used for sequence modeling tasks, such as language modeling, speech recognition, and time-series prediction.\",\n",
            "          \"indentation\": 2\n",
            "        }\n",
            "      ],\n",
            "      \"title\": \"Core Definition and Purpose\"\n",
            "    },\n",
            "    {\n",
            "      \"type\": \"item\",\n",
            "      \"number\": \"2\",\n",
            "      \"title\": \"Key Principles\",\n",
            "      \"subitems\": [\n",
            "        {\n",
            "          \"type\": \"item\",\n",
            "          \"number\": \"1\",\n",
            "          \"content\": [\n",
            "            {\n",
            "              \"type\": \"text\",\n",
            "              \"content\": \"LSTMs introduce memory cells and gates (input, output, and forget gates) to control the flow of information.\"\n",
            "            }\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"type\": \"item\",\n",
            "          \"number\": \"2\",\n",
            "          \"content\": [\n",
            "            {\n",
            "              \"type\": \"text\",\n",
            "              \"content\": \"These components allow the network to learn long-term dependencies by selectively retaining or discarding information.\"\n",
            "            }\n",
            "          ]\n",
            "        }\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"type\": \"item\",\n",
            "      \"number\": \"3\",\n",
            "      \"title\": \"Relationship to Broader Computing Concepts\",\n",
            "      \"subitems\": [\n",
            "        {\n",
            "          \"type\": \"item\",\n",
            "          \"number\": \"1\",\n",
            "          \"content\": [\n",
            "            {\n",
            "              \"type\": \"text\",\n",
            "              \"content\": \"LSTMs are a part of deep learning and neural networks, extending the capabilities of RNNs.\"\n",
            "            }\n",
            "          ]\n",
            "        },\n",
            "        {\n",
            "          \"type\": \"item\",\n",
            "          \"number\": \"2\",\n",
            "          \"content\": [\n",
            "            {\n",
            "              \"type\": \"text\",\n",
            "              \"content\": \"They are particularly useful for sequential data, where temporal relationships are important.\"\n",
            "            }\n",
            "          ]\n",
            "        }\n",
            "      ]\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Images Getter\n"
      ],
      "metadata": {
        "id": "H4_Cv5udHICe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from groq import Groq\n",
        "\n",
        "class GroqClient:\n",
        "    def __init__(self, api_key):\n",
        "        self.client = Groq(api_key=api_key)\n",
        "\n",
        "    def get_completion(self, query, max_tokens=2500):\n",
        "        prompt = self._construct_prompt(query)\n",
        "\n",
        "        try:\n",
        "            chat_completion = self.client.chat.completions.create(\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are a technical visualization expert specialized in extracting image search keywords.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": prompt\n",
        "                    }\n",
        "                ],\n",
        "                model=\"deepseek-r1-distill-llama-70b\",\n",
        "                temperature=0.5,\n",
        "                max_tokens=max_tokens,\n",
        "                top_p=0.7,\n",
        "                stream=False\n",
        "            )\n",
        "            return chat_completion.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"API request failed: {str(e)}\")\n",
        "\n",
        "    def _construct_prompt(self, content):\n",
        "        return f\"\"\"Extract specific image search keywords from the following content:\n",
        "\n",
        "{content}\n",
        "\n",
        "Your task: Generate 5-7 image search keywords that would help find educational diagrams and technical visualizations related to the main concepts in this content.\n",
        "\n",
        "Focus on identifying keywords for:\n",
        "1. System/concept architecture diagrams\n",
        "2. Process flows and sequences\n",
        "3. Component interactions\n",
        "4. Implementation details\n",
        "5. Working mechanisms\n",
        "6. Step-by-step procedures\n",
        "7. Technical examples\n",
        "\n",
        "Keyword Generation Rules:\n",
        "1. Each keyword MUST use hyphens between words\n",
        "2. Each keyword MUST end with exactly ONE of these suffixes:\n",
        "   - -visualization\n",
        "   - -diagram\n",
        "   - -illustration\n",
        "   - -example\n",
        "   - -steps\n",
        "\n",
        "Key Requirements:\n",
        "- Use specific technical terms from the content\n",
        "- Include major concepts and processes\n",
        "- Avoid generic/non-specific terms\n",
        "- Keywords must directly relate to main topics\n",
        "- Each keyword should help find relevant technical diagrams\n",
        "\n",
        "Output Format:\n",
        "ONLY provide a comma-separated list of keywords.\n",
        "Example: concept-architecture-diagram, process-flow-visualization, component-interaction-illustration\n",
        "\n",
        "KEYWORDS (comma-separated):\"\"\"\n",
        "\n",
        "def extract_keywords(response_text):\n",
        "    \"\"\"\n",
        "    Extracts and validates keywords from the API response.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        valid_suffixes = [\n",
        "            '-visualization',\n",
        "            '-diagram',\n",
        "            '-illustration',\n",
        "            '-example',\n",
        "            '-steps'\n",
        "        ]\n",
        "\n",
        "        # Get the comma-separated keywords\n",
        "        keywords = response_text.strip()\n",
        "\n",
        "        # Clean up and validate the keywords\n",
        "        cleaned_keywords = []\n",
        "        for keyword in keywords.split(','):\n",
        "            keyword = keyword.strip()\n",
        "\n",
        "            # Validation checks\n",
        "            if (keyword and                # Not empty\n",
        "                '-' in keyword and         # Contains hyphens\n",
        "                any(keyword.endswith(suffix) for suffix in valid_suffixes) and  # Has valid suffix\n",
        "                keyword.count('-') >= 2):  # Has at least 2 hyphens\n",
        "\n",
        "                cleaned_keywords.append(keyword)\n",
        "\n",
        "        # Return 5-7 keywords\n",
        "        cleaned_keywords = cleaned_keywords[:7] if len(cleaned_keywords) > 7 else cleaned_keywords\n",
        "\n",
        "        if len(cleaned_keywords) < 5:\n",
        "            print(f\"Not enough valid keywords found: {len(cleaned_keywords)}\")\n",
        "            return \"\"\n",
        "\n",
        "        return ', '.join(cleaned_keywords)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting keywords: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "    # Initialize client with your API key\n",
        "client = GroqClient(\"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\")\n",
        "\n",
        "\n",
        "try:\n",
        "        # Get completion from Groq\n",
        "        response = client.get_completion(result)\n",
        "\n",
        "        # Extract and validate keywords\n",
        "        keywords = extract_keywords(response)\n",
        "\n",
        "        print(\"Generated Image Search Keywords:\")\n",
        "        print(keywords)\n",
        "\n",
        "except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xd9KexXWHHQf",
        "outputId": "db8a55d2-96a2-4040-8c13-5d15305547db"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Image Search Keywords:\n",
            "and applications.\n",
            "</think>\n",
            "\n",
            "lstm-architecture-diagram, lstm-memory-cell-diagram, gate-interactions-visualization, lstm-working-mechanism-illustration, cell-state-update-steps, forward-pass-visualization, bidirectional-lstm-diagram\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keywords = extract_answer(keywords)"
      ],
      "metadata": {
        "id": "4RavNVNVbQFI"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(keywords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLrHWZIebhBR",
        "outputId": "2c984d0a-8f71-4423-a730-2b6384ec1cd7"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lstm-architecture-diagram, lstm-memory-cell-diagram, gate-interactions-visualization, lstm-working-mechanism-illustration, cell-state-update-steps, forward-pass-visualization, bidirectional-lstm-diagram\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_keywords(response_text):\n",
        "    \"\"\"\n",
        "    Extracts keywords from the API response by separating them using commas.\n",
        "    If the response includes a header, it is removed before splitting.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Remove header if present\n",
        "        if \"KEYWORDS (comma-separated):\" in response_text:\n",
        "            response_text = response_text.split(\"KEYWORDS (comma-separated):\")[-1].strip()\n",
        "\n",
        "        # Split on commas and remove any extra whitespace\n",
        "        keywords_list = [keyword.strip() for keyword in response_text.split(\",\") if keyword.strip()]\n",
        "        return keywords_list\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting keywords: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# Example usage:\n",
        "\n",
        "keywords = extract_keywords(keywords)\n",
        "print(\"Extracted Keywords List:\", keywords)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYJfYaW-Oii7",
        "outputId": "884422ba-e4cb-481f-fa61-e9ad2864108e"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Keywords List: ['lstm-architecture-diagram', 'lstm-memory-cell-diagram', 'gate-interactions-visualization', 'lstm-working-mechanism-illustration', 'cell-state-update-steps', 'forward-pass-visualization', 'bidirectional-lstm-diagram']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import requests\n",
        "from pptx import Presentation\n",
        "from pptx.util import Inches, Pt\n",
        "from pptx.enum.text import PP_ALIGN\n",
        "from pptx.dml.color import RGBColor\n",
        "\n",
        "def scrape_images(keyword, num_images=1):\n",
        "    \"\"\"Scrape images from GeeksForGeeks using SERP API\"\"\"\n",
        "    api_key = \"df7729cfcc6f85cfea8e18cb9f13ce5180a3ea6e1c22e2e5f3de3ea16bd6e40b\"\n",
        "\n",
        "    params = {\n",
        "        \"engine\": \"google_images\",\n",
        "        \"q\": keyword,\n",
        "        \"google_domain\": \"google.com\",\n",
        "        \"gl\": \"us\",\n",
        "        \"hl\": \"en\",\n",
        "        \"api_key\": api_key,\n",
        "    }\n",
        "\n",
        "    response = requests.get(\"https://serpapi.com/search.json\", params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        images = []\n",
        "\n",
        "        if \"images_results\" in data:\n",
        "            for image in data[\"images_results\"]:\n",
        "                if 'geeksforgeeks' in image.get('source', '').lower():\n",
        "                    images.append(image[\"original\"])\n",
        "                    if len(images) >= num_images:\n",
        "                        break\n",
        "            return images\n",
        "\n",
        "        return []\n",
        "    else:\n",
        "        print(f\"Failed to retrieve images. Status code: {response.status_code}\")\n",
        "        return []\n",
        "images = set()\n",
        "\n",
        "try:\n",
        "    for kw in keywords:\n",
        "        print(f\"\\nImages for '{kw}':\")\n",
        "        image_urls = scrape_images(kw)\n",
        "        print(image_urls)\n",
        "        if image_urls:  # Ensure there is at least one URL\n",
        "            images.add(image_urls[0])\n",
        "except Exception as e:\n",
        "    print(f\"Error: {str(e)}\")\n",
        "\n",
        "print(\"Collected image URLs:\", images)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6KQXnydK5zY",
        "outputId": "01beff34-a137-4022-e4ee-df3c92f7a998"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Images for 'lstm-architecture-diagram':\n",
            "['https://media.geeksforgeeks.org/wp-content/uploads/20240208053129/lstm.webp']\n",
            "\n",
            "Images for 'lstm-memory-cell-diagram':\n",
            "['https://media.geeksforgeeks.org/wp-content/uploads/20240208053129/lstm.webp']\n",
            "\n",
            "Images for 'gate-interactions-visualization':\n",
            "[]\n",
            "\n",
            "Images for 'lstm-working-mechanism-illustration':\n",
            "['https://media.geeksforgeeks.org/wp-content/uploads/20240208053129/lstm.webp']\n",
            "\n",
            "Images for 'cell-state-update-steps':\n",
            "['https://media.geeksforgeeks.org/wp-content/uploads/20240208104902/bruh.webp']\n",
            "\n",
            "Images for 'forward-pass-visualization':\n",
            "['https://media.geeksforgeeks.org/wp-content/uploads/20240425175947/Capture.PNG']\n",
            "\n",
            "Images for 'bidirectional-lstm-diagram':\n",
            "['https://media.geeksforgeeks.org/wp-content/uploads/20230529103946/Bidirectional-LSTM-(1)-660.jpg']\n",
            "Collected image URLs: {'https://media.geeksforgeeks.org/wp-content/uploads/20230529103946/Bidirectional-LSTM-(1)-660.jpg', 'https://media.geeksforgeeks.org/wp-content/uploads/20240425175947/Capture.PNG', 'https://media.geeksforgeeks.org/wp-content/uploads/20240208053129/lstm.webp', 'https://media.geeksforgeeks.org/wp-content/uploads/20240208104902/bruh.webp'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def merge_latex_fragments(content_items):\n",
        "    \"\"\"\n",
        "    Merge adjacent text items that form a single LaTeX expression.\n",
        "    Supports delimiters: '$', '$$', '\\\\[' and '\\\\]'.\n",
        "    \"\"\"\n",
        "    merged_items = []\n",
        "    i = 0\n",
        "    # Mapping of opening to closing delimiters.\n",
        "    delimiters = {\"\\\\[\": \"\\\\]\", \"$\": \"$\", \"$$\": \"$$\"}\n",
        "\n",
        "    while i < len(content_items):\n",
        "        item = content_items[i]\n",
        "        # Check if this text item is an opening delimiter exactly.\n",
        "        if item.get(\"type\") == \"text\" and item.get(\"content\") in delimiters:\n",
        "            open_delim = item[\"content\"]\n",
        "            close_delim = delimiters[open_delim]\n",
        "            indentation = item.get(\"indentation\", 0)\n",
        "            math_block = open_delim  # start with the opening delimiter\n",
        "            i += 1\n",
        "            # Collect all subsequent text items until the matching closing delimiter is found.\n",
        "            while i < len(content_items):\n",
        "                next_item = content_items[i]\n",
        "                # If we hit the closing delimiter exactly, add it and break.\n",
        "                if next_item.get(\"type\") == \"text\" and next_item.get(\"content\") == close_delim:\n",
        "                    math_block += next_item[\"content\"]\n",
        "                    i += 1\n",
        "                    break\n",
        "                else:\n",
        "                    # Otherwise, concatenate the text.\n",
        "                    math_block += next_item.get(\"content\", \"\")\n",
        "                    i += 1\n",
        "            # Append the merged LaTeX block as a single item.\n",
        "            merged_items.append({\n",
        "                \"type\": \"text\",\n",
        "                \"content\": math_block,\n",
        "                \"indentation\": indentation\n",
        "            })\n",
        "        else:\n",
        "            # Otherwise, just keep the item as is.\n",
        "            merged_items.append(item)\n",
        "            i += 1\n",
        "    return merged_items\n",
        "\n",
        "def process_json_obj(obj):\n",
        "    \"\"\"\n",
        "    Recursively traverse the JSON object.\n",
        "    When a 'content' list is found, merge its LaTeX fragments.\n",
        "    Also processes any 'items' or 'subitems' lists.\n",
        "    \"\"\"\n",
        "    if isinstance(obj, dict):\n",
        "        # Process a 'content' list if present.\n",
        "        if \"content\" in obj and isinstance(obj[\"content\"], list):\n",
        "            obj[\"content\"] = merge_latex_fragments(obj[\"content\"])\n",
        "        # Process nested lists under keys like 'items' and 'subitems'.\n",
        "        for key in [\"items\", \"subitems\"]:\n",
        "            if key in obj and isinstance(obj[key], list):\n",
        "                for item in obj[key]:\n",
        "                    process_json_obj(item)\n",
        "        # Also process any other dictionary values.\n",
        "        for value in obj.values():\n",
        "            process_json_obj(value)\n",
        "    elif isinstance(obj, list):\n",
        "        for item in obj:\n",
        "            process_json_obj(item)\n",
        "    return obj\n",
        "\n",
        "# Example: load your complete JSON file, process it, and save the result.\n",
        "if __name__ == \"__main__\":\n",
        "    input_file = \"output.json\"  # your JSON filename\n",
        "    output_file = \"output_merged.json\"  # file to save the merged version\n",
        "\n",
        "    with open(input_file, 'r', encoding=\"utf-8\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # Process the JSON to merge LaTeX fragments.\n",
        "    processed_data = process_json_obj(data)\n",
        "\n",
        "    # Optionally, write the processed JSON back to disk.\n",
        "    with open(output_file, 'w', encoding=\"utf-8\") as f:\n",
        "        json.dump(processed_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"Merged JSON saved as {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw5mm7q3dcW0",
        "outputId": "efa7548a-2aec-4480-adc7-1395fc8e7296"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged JSON saved as output_merged.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Equations to Latex"
      ],
      "metadata": {
        "id": "xzoMc7gddj3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy\n",
        "\n",
        "def clean_equation(equation):\n",
        "    \"\"\"Extract equation from various formats\"\"\"\n",
        "    # Try different equation delimiters\n",
        "    patterns = [\n",
        "        r'\\$(.+?)\\$',           # $...$\n",
        "        r'\\\\\\((.+?)\\\\\\)',       # \\(...\\)\n",
        "        r'\\\\text\\{(.+?)\\}',     # \\text{...}\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, equation)\n",
        "        if match:\n",
        "            return match.group(1).strip()\n",
        "\n",
        "    # If no patterns match, return cleaned original text\n",
        "    return equation.split(\":\")[1].strip() if \":\" in equation else equation.strip()\n",
        "\n",
        "def render_equation(latex_equation, index):\n",
        "    \"\"\"Render equation using matplotlib's math text\"\"\"\n",
        "    file_path = f\"equation_{index + 1}.png\"\n",
        "\n",
        "    # Create figure\n",
        "    plt.figure(figsize=(10, 2), facecolor='white')\n",
        "    ax = plt.gca()\n",
        "    ax.set_facecolor('white')\n",
        "\n",
        "    # Render the equation\n",
        "    plt.text(0.5, 0.5, f\"${latex_equation}$\",\n",
        "             size=14,\n",
        "             ha='center',\n",
        "             va='center',\n",
        "             transform=ax.transAxes)\n",
        "\n",
        "    # Remove axes\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Save with tight layout\n",
        "    plt.savefig(file_path,\n",
        "                bbox_inches='tight',\n",
        "                pad_inches=0.1,\n",
        "                dpi=300,\n",
        "                facecolor='white')\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Rendered equation saved as '{file_path}'\")\n",
        "    return file_path\n",
        "\n",
        "def process_equations(data):\n",
        "    \"\"\"Process all equations in the JSON data\"\"\"\n",
        "    updated_data = deepcopy(data)\n",
        "\n",
        "    # Find equations in all sections\n",
        "    for section in updated_data.values():\n",
        "        if isinstance(section, dict) and \"items\" in section:\n",
        "            for item in section[\"items\"]:\n",
        "                if \"content\" in item:\n",
        "                    # Process direct content\n",
        "                    for content_item in item[\"content\"]:\n",
        "                        if isinstance(content_item, dict) and \"content\" in content_item:\n",
        "                            text = content_item[\"content\"]\n",
        "                            if \"$\" in text or \"\\\\(\" in text:\n",
        "                                print(f\"\\nProcessing equation:\\nRaw: {text}\")\n",
        "                                math_expr = clean_equation(text)\n",
        "                                print(f\"Cleaned: {math_expr}\")\n",
        "                                png_path = render_equation(math_expr,\n",
        "                                                        hash(text) % 1000)  # Unique index\n",
        "                                content_item[\"content\"] = png_path\n",
        "                                content_item[\"type\"] = \"equation_image\"\n",
        "\n",
        "                # Process subitems\n",
        "                if \"subitems\" in item:\n",
        "                    for subitem in item[\"subitems\"]:\n",
        "                        if \"content\" in subitem:\n",
        "                            for content_item in subitem[\"content\"]:\n",
        "                                if isinstance(content_item, dict) and \"content\" in content_item:\n",
        "                                    text = content_item[\"content\"]\n",
        "                                    if \"$\" in text or \"\\\\(\" in text:\n",
        "                                        print(f\"\\nProcessing equation:\\nRaw: {text}\")\n",
        "                                        math_expr = clean_equation(text)\n",
        "                                        print(f\"Cleaned: {math_expr}\")\n",
        "                                        png_path = render_equation(math_expr,\n",
        "                                                                hash(text) % 1000)\n",
        "                                        content_item[\"content\"] = png_path\n",
        "                                        content_item[\"type\"] = \"equation_image\"\n",
        "\n",
        "    return updated_data\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load the JSON file\n",
        "    with open('output.json', 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Process the equations\n",
        "    updated_data = process_equations(data)\n",
        "\n",
        "    # Save the updated JSON structure\n",
        "    with open('output_updated.json', 'w') as file:\n",
        "        json.dump(updated_data, file, indent=4)\n",
        "        print(\"\\nUpdated JSON saved to 'output_updated.json'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMdEDUCBU3AF",
        "outputId": "75764dfc-8528-4e39-8f80-ec8dbe8f3490"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing equation:\n",
            "Raw: Let \\( f_t \\), \\( i_t \\), and \\( o_t \\) represent the forget, input, and output gates, respectively. Let \\( c_t \\) and \\( h_t \\) denote the cell state and hidden state at time \\( t \\). The key equations are:\n",
            "Cleaned: f_t\n",
            "Rendered equation saved as 'equation_288.png'\n",
            "\n",
            "Processing equation:\n",
            "Raw: Where \\( \\sigma \\) is the sigmoid function, \\( \\tanh \\) is the hyperbolic tangent function, and \\( \\odot \\) denotes element-wise multiplication.\n",
            "Cleaned: \\sigma\n",
            "Rendered equation saved as 'equation_855.png'\n",
            "\n",
            "Processing equation:\n",
            "Raw: \\( f_t = \\sigma(W_f x_t + U_f h_{t-1} + b_f) \\)\n",
            "Cleaned: f_t = \\sigma(W_f x_t + U_f h_{t-1} + b_f)\n",
            "Rendered equation saved as 'equation_305.png'\n",
            "\n",
            "Processing equation:\n",
            "Raw: \\( i_t = \\sigma(W_i x_t + U_i h_{t-1} + b_i) \\)\n",
            "Cleaned: i_t = \\sigma(W_i x_t + U_i h_{t-1} + b_i)\n",
            "Rendered equation saved as 'equation_523.png'\n",
            "\n",
            "Processing equation:\n",
            "Raw: \\( o_t = \\sigma(W_o x_t + U_o h_{t-1} + b_o) \\)\n",
            "Cleaned: o_t = \\sigma(W_o x_t + U_o h_{t-1} + b_o)\n",
            "Rendered equation saved as 'equation_283.png'\n",
            "\n",
            "Processing equation:\n",
            "Raw: \\( c_t = f_t \\odot c_{t-1} + i_t \\odot \\tanh(W_c x_t + U_c h_{t-1} + b_c) \\)\n",
            "Cleaned: c_t = f_t \\odot c_{t-1} + i_t \\odot \\tanh(W_c x_t + U_c h_{t-1} + b_c)\n",
            "Rendered equation saved as 'equation_693.png'\n",
            "\n",
            "Processing equation:\n",
            "Raw: \\( h_t = o_t \\odot \\tanh(c_t) \\)\n",
            "Cleaned: h_t = o_t \\odot \\tanh(c_t)\n",
            "Rendered equation saved as 'equation_819.png'\n",
            "\n",
            "Processing equation:\n",
            "Raw: The input \\( x_t \\) is processed along with the previous hidden state \\( h_{t-1} \\) to compute the gates.\n",
            "Cleaned: x_t\n",
            "Rendered equation saved as 'equation_596.png'\n",
            "\n",
            "Processing equation:\n",
            "Raw: The cell state \\( c_t \\) is updated based on the forget gate and the input gate.\n",
            "Cleaned: c_t\n",
            "Rendered equation saved as 'equation_509.png'\n",
            "\n",
            "Processing equation:\n",
            "Raw: The hidden state \\( h_t \\) is computed using the output gate and the cell state.\n",
            "Cleaned: h_t\n",
            "Rendered equation saved as 'equation_530.png'\n",
            "\n",
            "Updated JSON saved to 'output_updated.json'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "updated_data[\"Section 2\"][\"items\"]#[[\"title\"]==\"Mathematical Equations\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwpGagVSs9Mf",
        "outputId": "77961c5b-ef7b-494e-f5f4-a48541804492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'type': 'item',\n",
              "  'number': '1',\n",
              "  'title': 'Primary elements and their roles',\n",
              "  'subitems': [{'type': 'item',\n",
              "    'number': '1',\n",
              "    'content': [{'type': 'text',\n",
              "      'content': 'Maintains records of which transactions hold locks on which items. It includes fields like data item name, number of read locks, and the transaction holding a write lock.'}],\n",
              "    'title': 'Lock Table'},\n",
              "   {'type': 'item',\n",
              "    'number': '2',\n",
              "    'content': [{'type': 'text',\n",
              "      'content': 'Responsible for granting, releasing, and managing locks. It enforces the rules of the locking protocol.'}],\n",
              "    'title': 'Lock Manager'},\n",
              "   {'type': 'item',\n",
              "    'number': '3',\n",
              "    'content': [{'type': 'text',\n",
              "      'content': 'Entities that request locks to access data items.'}],\n",
              "    'title': 'Transactions'}]},\n",
              " {'type': 'item',\n",
              "  'number': '2',\n",
              "  'content': [{'type': 'text',\n",
              "    'content': 'Transactions interact with the lock manager to acquire and release locks. The lock table reflects the current state of locks on data items.'}],\n",
              "  'title': 'Relationships and interactions'},\n",
              " {'type': 'item',\n",
              "  'number': '3',\n",
              "  'content': [{'type': 'text',\n",
              "    'content': 'Locks can be shared (for read operations) or exclusive (for write operations). The lock manager ensures that shared locks can be held by multiple transactions, while exclusive locks are held by a single transaction.'}],\n",
              "  'title': 'Implementation details'},\n",
              " {'type': 'item',\n",
              "  'number': '4',\n",
              "  'title': 'Core algorithms/procedures',\n",
              "  'subitems': [{'type': 'item',\n",
              "    'number': '1',\n",
              "    'content': [{'type': 'text',\n",
              "      'content': 'Acquired before a read operation. Multiple transactions can hold shared locks.'}],\n",
              "    'title': 'Read_Lock'},\n",
              "   {'type': 'item',\n",
              "    'number': '2',\n",
              "    'content': [{'type': 'text',\n",
              "      'content': 'Acquired before a write operation. Only one transaction can hold an exclusive lock.'}],\n",
              "    'title': 'Write_Lock'},\n",
              "   {'type': 'item',\n",
              "    'number': '3',\n",
              "    'content': [{'type': 'text',\n",
              "      'content': 'Releases the lock, allowing other transactions to acquire it.'}],\n",
              "    'title': 'Unlock'}]}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#JSON to PPT(DONT RUN THIS. THIS IS PREVIOUS CODE. BELOW THIS CODE IS NEW CODE.)"
      ],
      "metadata": {
        "id": "ypOtqHe7gr3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pptx import Presentation\n",
        "from pptx.util import Inches, Pt\n",
        "from pptx.enum.text import PP_ALIGN\n",
        "from pptx.dml.color import RGBColor\n",
        "import json\n",
        "\n",
        "class JSONToPPTXConverter:\n",
        "    def __init__(self):\n",
        "        self.prs = Presentation()\n",
        "        self.toc_items = []\n",
        "        self.min_points_per_slide = 3\n",
        "        self.max_points_per_slide = 5\n",
        "\n",
        "    def add_title_slide(self, title):\n",
        "        \"\"\"Add a title slide at the beginning of the presentation.\"\"\"\n",
        "        title_slide_layout = self.prs.slide_layouts[0]\n",
        "        slide = self.prs.slides.add_slide(title_slide_layout)\n",
        "        title_shape = slide.shapes.title\n",
        "        title_shape.text_frame.text = title\n",
        "        title_shape.text_frame.paragraphs[0].font.size = Pt(44)\n",
        "        title_shape.text_frame.paragraphs[0].font.bold = True\n",
        "\n",
        "    def add_table_of_contents_slide(self):\n",
        "        \"\"\"Add a table of contents slide.\"\"\"\n",
        "        toc_slide_layout = self.prs.slide_layouts[1]\n",
        "        slide = self.prs.slides.add_slide(toc_slide_layout)\n",
        "\n",
        "        title_shape = slide.shapes.title\n",
        "        title_shape.text_frame.text = \"Table of Contents\"\n",
        "        title_shape.text_frame.paragraphs[0].font.size = Pt(40)\n",
        "        title_shape.text_frame.paragraphs[0].font.bold = True\n",
        "\n",
        "        body_shape = slide.placeholders[1]\n",
        "        text_frame = body_shape.text_frame\n",
        "        text_frame.clear()\n",
        "\n",
        "        for item in self.toc_items:\n",
        "            p = text_frame.add_paragraph()\n",
        "            p.text = f\"{item['number']}. {item['title']}\"\n",
        "            p.font.size = Pt(26)\n",
        "            p.space_after = Pt(6)\n",
        "\n",
        "    def group_content_by_title(self, title, content):\n",
        "        \"\"\"Group content into chunks of 2-3 items per slide, maintaining the same title.\"\"\"\n",
        "        if not isinstance(content, list):\n",
        "            content = [content]\n",
        "\n",
        "        grouped_slides = []\n",
        "        current_group = []\n",
        "\n",
        "        for item in content:\n",
        "            current_group.append(item)\n",
        "            if len(current_group) >= self.max_points_per_slide:\n",
        "                grouped_slides.append((title, current_group))\n",
        "                current_group = []\n",
        "\n",
        "        # Handle remaining items\n",
        "        if current_group:\n",
        "            if len(current_group) < self.min_points_per_slide and grouped_slides:\n",
        "                # Try to combine with the last group if it won't exceed max\n",
        "                last_group = grouped_slides[-1][1]\n",
        "                if len(last_group) + len(current_group) <= self.max_points_per_slide:\n",
        "                    last_group.extend(current_group)\n",
        "                else:\n",
        "                    grouped_slides.append((title, current_group))\n",
        "            else:\n",
        "                grouped_slides.append((title, current_group))\n",
        "\n",
        "        return grouped_slides\n",
        "\n",
        "    def add_text_to_frame(self, text_frame, content, font_size=30, font_name='Calibri'):\n",
        "        \"\"\"Helper method to add text to a text frame.\"\"\"\n",
        "        p = text_frame.add_paragraph()\n",
        "        p.text = str(content)\n",
        "        p.font.size = Pt(font_size)\n",
        "        p.font.name = font_name\n",
        "        return p\n",
        "\n",
        "    def create_content_slide(self, title, content_group, slide_layout_idx=1):\n",
        "        \"\"\"Create a single content slide with the given title and content group.\"\"\"\n",
        "        slide_layout = self.prs.slide_layouts[slide_layout_idx]\n",
        "        slide = self.prs.slides.add_slide(slide_layout)\n",
        "\n",
        "        # Add title\n",
        "        title_shape = slide.shapes.title\n",
        "        title_shape.text_frame.text = title\n",
        "        title_para = title_shape.text_frame.paragraphs[0]\n",
        "        title_para.font.size = Pt(36)\n",
        "        title_para.font.bold = True\n",
        "\n",
        "        # Add content\n",
        "        body_shape = slide.placeholders[1]\n",
        "        text_frame = body_shape.text_frame\n",
        "        text_frame.clear()\n",
        "\n",
        "        for item in content_group:\n",
        "            if isinstance(item, dict):\n",
        "                if 'type' in item and item['type'] == 'code':\n",
        "                    self.add_text_to_frame(\n",
        "                        text_frame,\n",
        "                        f\"Code ({item.get('language', '')}):\\n{item['content']}\",\n",
        "                        font_size=10,\n",
        "                        font_name='Courier New'\n",
        "                    )\n",
        "                elif 'type' in item and item['type'] == 'text':\n",
        "                    self.add_text_to_frame(text_frame, item['content'])\n",
        "            else:\n",
        "                self.add_text_to_frame(text_frame, item)\n",
        "\n",
        "    def process_section(self, section_data):\n",
        "        \"\"\"Process a section and its items, grouping content by title.\"\"\"\n",
        "        self.toc_items.append({\n",
        "            'number': section_data['number'],\n",
        "            'title': section_data['title']\n",
        "        })\n",
        "\n",
        "        section_title = f\"Section {section_data['number']}: {section_data['title']}\"\n",
        "\n",
        "        for item in section_data['items']:\n",
        "            item_title = f\"{section_data['title']} - {item.get('title', '')}\"\n",
        "\n",
        "            if 'content' in item:\n",
        "                # Group content for this item\n",
        "                grouped_slides = self.group_content_by_title(item_title, item['content'])\n",
        "                for title, content_group in grouped_slides:\n",
        "                    self.create_content_slide(title, content_group)\n",
        "\n",
        "            if 'subitems' in item and item['subitems']:\n",
        "                for subitem in item['subitems']:\n",
        "                    subitem_content = subitem.get('content', [])\n",
        "                    if subitem.get('title'):\n",
        "                        subitem_title = f\"{item_title} - {subitem['title']}\"\n",
        "                    else:\n",
        "                        subitem_title = f\"{item_title} - {subitem.get('number', '')}\"\n",
        "\n",
        "                    if subitem_content:\n",
        "                        # Group content for this subitem\n",
        "                        grouped_slides = self.group_content_by_title(subitem_title, subitem_content)\n",
        "                        for title, content_group in grouped_slides:\n",
        "                            self.create_content_slide(title, content_group)\n",
        "\n",
        "    def _move_last_slide_to_index(self, index):\n",
        "        \"\"\"Move the last slide to the specified index.\"\"\"\n",
        "        sldIdLst = self.prs.slides._sldIdLst\n",
        "        slides_ids = list(sldIdLst)\n",
        "        last_slide_id = slides_ids[-1]\n",
        "        sldIdLst.remove(last_slide_id)\n",
        "        sldIdLst.insert(index, last_slide_id)\n",
        "\n",
        "    def convert_json_to_pptx(self, json_data, output_filename='output.pptx'):\n",
        "        \"\"\"Convert JSON data to PowerPoint presentation.\"\"\"\n",
        "        self.add_title_slide(output_filename.split('.')[0].upper())\n",
        "\n",
        "        for section_key, section_data in json_data.items():\n",
        "            if section_data['type'] == 'section':\n",
        "                self.process_section(section_data)\n",
        "\n",
        "        self.add_table_of_contents_slide()\n",
        "        self._move_last_slide_to_index(1)\n",
        "\n",
        "        self.prs.save(output_filename)\n",
        "\n",
        "def main():\n",
        "    with open('output.json', 'r') as file:\n",
        "        json_data = json.load(file)\n",
        "\n",
        "    converter = JSONToPPTXConverter()\n",
        "    converter.convert_json_to_pptx(json_data, query.upper()+'.pptx')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "IBwgvEy8gus0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#JSON to PPT Final"
      ],
      "metadata": {
        "id": "q12qC2-cRwz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pptx import Presentation\n",
        "from pptx.util import Inches, Pt\n",
        "from pptx.enum.text import PP_ALIGN\n",
        "from pptx.dml.color import RGBColor\n",
        "from pptx.enum.text import MSO_AUTO_SIZE\n",
        "\n",
        "class PPTGenerator:\n",
        "    def __init__(self):\n",
        "        self.prs = Presentation(\"/content/Crop.pptx\")\n",
        "        self.slide_width = self.prs.slide_width\n",
        "        self.slide_height = self.prs.slide_height\n",
        "        self.slide_count = 0\n",
        "\n",
        "        # Color scheme\n",
        "        self.colors = {\n",
        "            'title': RGBColor(44, 62, 80),      # Dark blue\n",
        "            'subtitle': RGBColor(52, 73, 94),    # Lighter blue\n",
        "            'body': RGBColor(44, 62, 80),        # Dark blue\n",
        "            'code': RGBColor(46, 204, 113),      # Green\n",
        "            'slide_number': RGBColor(149, 165, 166)  # Gray\n",
        "        }\n",
        "\n",
        "    def add_slide_number(self, slide):\n",
        "        \"\"\"Add slide number to the bottom right corner\"\"\"\n",
        "        self.slide_count += 1\n",
        "        txBox = slide.shapes.add_textbox(\n",
        "            Inches(9), Inches(6.5), Inches(1), Inches(0.5))\n",
        "        tf = txBox.text_frame\n",
        "        p = tf.paragraphs[0]\n",
        "        p.text = f\"Slide {self.slide_count}\"\n",
        "        p.alignment = PP_ALIGN.RIGHT\n",
        "        p.font.size = Pt(12)\n",
        "        p.font.color.rgb = self.colors['slide_number']\n",
        "\n",
        "    def add_title_slide(self, title):\n",
        "        \"\"\"Add title slide\"\"\"\n",
        "        slide_layout = self.prs.slide_layouts[0]\n",
        "        slide = self.prs.slides.add_slide(slide_layout)\n",
        "\n",
        "        title_shape = slide.shapes.title\n",
        "        title_shape.text = title\n",
        "        title_shape.text_frame.paragraphs[0].font.color.rgb = self.colors['title']\n",
        "        title_shape.text_frame.paragraphs[0].font.size = Pt(44)\n",
        "\n",
        "        self.add_slide_number(slide)\n",
        "        return slide\n",
        "\n",
        "    def format_bullet_point(self, paragraph, level=0):\n",
        "        \"\"\"Format bullet point with proper indentation and style\"\"\"\n",
        "        paragraph.level = level\n",
        "        paragraph.font.size = Pt(25 - level)  # Decrease font size for deeper levels\n",
        "        paragraph.font.color.rgb = self.colors['body']\n",
        "        return paragraph\n",
        "\n",
        "    def add_content_slide(self, title, content_items, is_subsection=False):\n",
        "        \"\"\"Add content slide with proper bullet points and overflow management\"\"\"\n",
        "        slide_layout = self.prs.slide_layouts[1]\n",
        "        current_slide = self.prs.slides.add_slide(slide_layout)\n",
        "\n",
        "        # Add title\n",
        "        title_shape = current_slide.shapes.title\n",
        "        title_shape.text = title\n",
        "        title_shape.text_frame.paragraphs[0].font.color.rgb = self.colors['title']\n",
        "        title_shape.text_frame.paragraphs[0].font.size = Pt(32)\n",
        "\n",
        "        # Add content\n",
        "        content_shape = current_slide.placeholders[1]\n",
        "        tf = content_shape.text_frame\n",
        "        tf.word_wrap = True\n",
        "\n",
        "        # Clear default paragraph\n",
        "        tf.clear()\n",
        "\n",
        "        current_height = 0\n",
        "        max_height = Inches(5)  # Maximum content height\n",
        "\n",
        "        for item in content_items:\n",
        "            # Estimate text height\n",
        "            text_height = len(item.split()) * Pt(25) * 0.3  # Rough estimation\n",
        "\n",
        "            if current_height + text_height > max_height:\n",
        "                # Create new slide if content overflows\n",
        "                current_slide = self.prs.slides.add_slide(slide_layout)\n",
        "                title_shape = current_slide.shapes.title\n",
        "                title_shape.text = f\"{title} (continued)\"\n",
        "                title_shape.text_frame.paragraphs[0].font.color.rgb = self.colors['title']\n",
        "                title_shape.text_frame.paragraphs[0].font.size = Pt(32)\n",
        "\n",
        "                content_shape = current_slide.placeholders[1]\n",
        "                tf = content_shape.text_frame\n",
        "                tf.word_wrap = True\n",
        "                current_height = 0\n",
        "\n",
        "                self.add_slide_number(current_slide)\n",
        "\n",
        "            p = tf.add_paragraph()\n",
        "            p.text = item\n",
        "            self.format_bullet_point(p, 1 if is_subsection else 0)\n",
        "            current_height += text_height\n",
        "\n",
        "        self.add_slide_number(current_slide)\n",
        "        return current_slide\n",
        "\n",
        "    def add_code_slide(self, title, code):\n",
        "        \"\"\"Add code slide with proper formatting\"\"\"\n",
        "        slide_layout = self.prs.slide_layouts[1]\n",
        "        slide = self.prs.slides.add_slide(slide_layout)\n",
        "\n",
        "        # Add title\n",
        "        title_shape = slide.shapes.title\n",
        "        title_shape.text = title\n",
        "        title_shape.text_frame.paragraphs[0].font.color.rgb = self.colors['title']\n",
        "        title_shape.text_frame.paragraphs[0].font.size = Pt(32)\n",
        "\n",
        "        # Add code with text box for better control\n",
        "        left = Inches(2)\n",
        "        top = Inches(2.6)\n",
        "        width = Inches(8)\n",
        "        height = Inches(5)\n",
        "\n",
        "        textbox = slide.shapes.add_textbox(left, top, width, height)\n",
        "        tf = textbox.text_frame\n",
        "        tf.word_wrap = True\n",
        "\n",
        "        # Split code into smaller chunks if too long\n",
        "        code_lines = code.split('\\n')\n",
        "        lines_per_slide = 20\n",
        "\n",
        "        for i in range(0, len(code_lines), lines_per_slide):\n",
        "            if i > 0:\n",
        "                slide = self.prs.slides.add_slide(slide_layout)\n",
        "                title_shape = slide.shapes.title\n",
        "                title_shape.text = f\"{title} (continued)\"\n",
        "                title_shape.text_frame.paragraphs[0].font.color.rgb = self.colors['title']\n",
        "                textbox = slide.shapes.add_textbox(left, top, width, height)\n",
        "                tf = textbox.text_frame\n",
        "                tf.word_wrap = True\n",
        "\n",
        "            chunk = '\\n'.join(code_lines[i:i + lines_per_slide])\n",
        "            p = tf.add_paragraph()\n",
        "            p.text = chunk\n",
        "            p.font.name = 'Courier New'\n",
        "            p.font.size = Pt(11)\n",
        "            p.font.color.rgb = self.colors['code']\n",
        "\n",
        "            self.add_slide_number(slide)\n",
        "\n",
        "        return slide\n",
        "\n",
        "    def process_json_to_ppt(self, json_data):\n",
        "        \"\"\"Process JSON data and create PPT slides\"\"\"\n",
        "        # Add title slide\n",
        "        self.add_title_slide(query.upper())\n",
        "\n",
        "        for section_key, section_data in json_data.items():\n",
        "            section_title = section_data['title']\n",
        "            current_items = []\n",
        "\n",
        "            for item in section_data['items']:\n",
        "                if 'content' in item:\n",
        "                    # Handle regular content\n",
        "                    content_texts = []\n",
        "                    for content_item in item['content']:\n",
        "                        if isinstance(content_item, dict):\n",
        "                            if content_item['type'] == 'code':\n",
        "                                # First add any accumulated content\n",
        "                                if content_texts:\n",
        "                                    self.add_content_slide(f\"{section_title} - {item['title']}\", content_texts)\n",
        "                                    content_texts = []\n",
        "                                # Then add code slide\n",
        "                                self.add_code_slide(f\"{section_title} - {item['title']}\", content_item['content'])\n",
        "                            elif content_item['type'] == 'text':\n",
        "                                content_texts.append(content_item['content'])\n",
        "\n",
        "                    if content_texts:\n",
        "                        self.add_content_slide(f\"{section_title} - {item['title']}\", content_texts)\n",
        "\n",
        "                # Handle subitems\n",
        "                if 'subitems' in item:\n",
        "                    subitem_texts = []\n",
        "                    for subitem in item['subitems']:\n",
        "                        if 'content' in subitem:\n",
        "                            for content in subitem['content']:\n",
        "                                if isinstance(content, dict) and content['type'] == 'text':\n",
        "                                    title = f\"{subitem.get('title', '')}\"\n",
        "                                    if title:\n",
        "                                        subitem_texts.append(f\"{title}: {content['content']}\")\n",
        "                                    else:\n",
        "                                        subitem_texts.append(content['content'])\n",
        "\n",
        "                    if subitem_texts:\n",
        "                        self.add_content_slide(f\"{section_title} - {item['title']}\", subitem_texts, is_subsection=True)\n",
        "\n",
        "    def save(self, filename):\n",
        "        \"\"\"Save the presentation\"\"\"\n",
        "        self.prs.save(filename)\n",
        "\n",
        "def create_presentation(json_file_path, output_pptx_path):\n",
        "    \"\"\"Main function to create presentation from JSON\"\"\"\n",
        "    # Read JSON data\n",
        "    with open(json_file_path, 'r') as f:\n",
        "        json_data = json.load(f)\n",
        "\n",
        "    # Create and save presentation\n",
        "    ppt_gen = PPTGenerator()\n",
        "    ppt_gen.process_json_to_ppt(json_data)\n",
        "    ppt_gen.save(output_pptx_path)\n",
        "    print(f\"Presentation saved as {output_pptx_path}\")\n",
        "\n",
        "# Usage example\n",
        "if __name__ == \"__main__\":\n",
        "    create_presentation(\"output.json\", query.upper()+\".pptx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGWPzGXOMFqZ",
        "outputId": "7dd11224-8ca7-4f20-e937-931284170a72"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Presentation saved as LSTM.pptx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Image PPT"
      ],
      "metadata": {
        "id": "Tm3PBLliSWPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from io import BytesIO\n",
        "import os\n",
        "import requests\n",
        "from pptx import Presentation\n",
        "from pptx.util import Inches, Pt\n",
        "from pptx.enum.text import PP_ALIGN\n",
        "from pptx.dml.color import RGBColor\n",
        "from pptx.enum.text import MSO_AUTO_SIZE\n",
        "from PIL import Image\n",
        "\n",
        "class PPTGenerator:\n",
        "    def __init__(self, template_path=\"/content/Crop.pptx\"):\n",
        "        # Load template if available, else create a new presentation.\n",
        "        if os.path.exists(template_path):\n",
        "            self.prs = Presentation(template_path)\n",
        "        else:\n",
        "            print(f\"Template {template_path} not found. Creating a new presentation.\")\n",
        "            self.prs = Presentation()\n",
        "        self.slide_width = self.prs.slide_width  # in EMUs\n",
        "        self.slide_height = self.prs.slide_height  # in EMUs\n",
        "        self.slide_count = 0\n",
        "\n",
        "        # Color scheme\n",
        "        self.colors = {\n",
        "            'title': RGBColor(44, 62, 80),      # Dark blue\n",
        "            'subtitle': RGBColor(52, 73, 94),    # Lighter blue\n",
        "            'body': RGBColor(44, 62, 80),        # Dark blue\n",
        "            'code': RGBColor(46, 204, 113),      # Green\n",
        "            'slide_number': RGBColor(149, 165, 166)  # Gray\n",
        "        }\n",
        "\n",
        "    def add_slide_number(self, slide):\n",
        "        \"\"\"Add slide number to the bottom right corner.\"\"\"\n",
        "        self.slide_count += 1\n",
        "        txBox = slide.shapes.add_textbox(Inches(9), Inches(6.5), Inches(1), Inches(0.5))\n",
        "        tf = txBox.text_frame\n",
        "        p = tf.paragraphs[0]\n",
        "        p.text = f\"Slide {self.slide_count}\"\n",
        "        p.alignment = PP_ALIGN.RIGHT\n",
        "        p.font.size = Pt(12)\n",
        "        p.font.color.rgb = self.colors['slide_number']\n",
        "\n",
        "    def add_title_slide(self, title):\n",
        "        \"\"\"Add title slide.\"\"\"\n",
        "        slide_layout = self.prs.slide_layouts[0]\n",
        "        slide = self.prs.slides.add_slide(slide_layout)\n",
        "\n",
        "        title_shape = slide.shapes.title\n",
        "        title_shape.text = title\n",
        "        title_shape.text_frame.paragraphs[0].font.color.rgb = self.colors['title']\n",
        "        title_shape.text_frame.paragraphs[0].font.size = Pt(44)\n",
        "\n",
        "        self.add_slide_number(slide)\n",
        "        return slide\n",
        "\n",
        "    def format_bullet_point(self, paragraph, level=0):\n",
        "        \"\"\"Format bullet point with proper indentation and style.\"\"\"\n",
        "        paragraph.level = level\n",
        "        paragraph.font.size = Pt(25 - level)  # Decrease font size for deeper levels\n",
        "        paragraph.font.color.rgb = self.colors['body']\n",
        "        return paragraph\n",
        "\n",
        "    def add_content_slide(self, title, content_items, is_subsection=False):\n",
        "        \"\"\"Add content slide with bullet points and overflow management.\"\"\"\n",
        "        slide_layout = self.prs.slide_layouts[1]\n",
        "        current_slide = self.prs.slides.add_slide(slide_layout)\n",
        "\n",
        "        # Add title\n",
        "        title_shape = current_slide.shapes.title\n",
        "        title_shape.text = title\n",
        "        title_shape.text_frame.paragraphs[0].font.color.rgb = self.colors['title']\n",
        "        title_shape.text_frame.paragraphs[0].font.size = Pt(32)\n",
        "\n",
        "        # Add content from placeholder\n",
        "        content_shape = current_slide.placeholders[1]\n",
        "        tf = content_shape.text_frame\n",
        "        tf.word_wrap = True\n",
        "        tf.clear()\n",
        "\n",
        "        current_height = 0\n",
        "        max_height = Inches(5)  # Maximum content height\n",
        "\n",
        "        for item in content_items:\n",
        "            # Rough estimation of text height\n",
        "            text_height = len(item.split()) * Pt(25) * 0.3\n",
        "\n",
        "            if current_height + text_height > max_height:\n",
        "                # Create new slide if content overflows\n",
        "                current_slide = self.prs.slides.add_slide(slide_layout)\n",
        "                title_shape = current_slide.shapes.title\n",
        "                title_shape.text = f\"{title} (continued)\"\n",
        "                title_shape.text_frame.paragraphs[0].font.color.rgb = self.colors['title']\n",
        "                title_shape.text_frame.paragraphs[0].font.size = Pt(32)\n",
        "\n",
        "                content_shape = current_slide.placeholders[1]\n",
        "                tf = content_shape.text_frame\n",
        "                tf.word_wrap = True\n",
        "                current_height = 0\n",
        "\n",
        "                self.add_slide_number(current_slide)\n",
        "\n",
        "            p = tf.add_paragraph()\n",
        "            p.text = item\n",
        "            self.format_bullet_point(p, 1 if is_subsection else 0)\n",
        "            current_height += text_height\n",
        "\n",
        "        self.add_slide_number(current_slide)\n",
        "        return current_slide\n",
        "\n",
        "    def add_code_slide(self, title, code):\n",
        "        \"\"\"Add code slide with proper formatting.\"\"\"\n",
        "        slide_layout = self.prs.slide_layouts[1]\n",
        "        slide = self.prs.slides.add_slide(slide_layout)\n",
        "\n",
        "        # Add title\n",
        "        title_shape = slide.shapes.title\n",
        "        title_shape.text = title\n",
        "        title_shape.text_frame.paragraphs[0].font.color.rgb = self.colors['title']\n",
        "        title_shape.text_frame.paragraphs[0].font.size = Pt(32)\n",
        "\n",
        "        # Add code textbox\n",
        "        left = Inches(2)\n",
        "        top = Inches(2.6)\n",
        "        width = Inches(8)\n",
        "        height = Inches(5)\n",
        "\n",
        "        textbox = slide.shapes.add_textbox(left, top, width, height)\n",
        "        tf = textbox.text_frame\n",
        "        tf.word_wrap = True\n",
        "\n",
        "        # Split code into chunks if too long\n",
        "        code_lines = code.split('\\n')\n",
        "        lines_per_slide = 20\n",
        "\n",
        "        for i in range(0, len(code_lines), lines_per_slide):\n",
        "            if i > 0:\n",
        "                slide = self.prs.slides.add_slide(slide_layout)\n",
        "                title_shape = slide.shapes.title\n",
        "                title_shape.text = f\"{title} (continued)\"\n",
        "                title_shape.text_frame.paragraphs[0].font.color.rgb = self.colors['title']\n",
        "                textbox = slide.shapes.add_textbox(left, top, width, height)\n",
        "                tf = textbox.text_frame\n",
        "                tf.word_wrap = True\n",
        "\n",
        "            chunk = '\\n'.join(code_lines[i:i + lines_per_slide])\n",
        "            p = tf.add_paragraph()\n",
        "            p.text = chunk\n",
        "            p.font.name = 'Courier New'\n",
        "            p.font.size = Pt(11)\n",
        "            p.font.color.rgb = self.colors['code']\n",
        "\n",
        "            self.add_slide_number(slide)\n",
        "\n",
        "        return slide\n",
        "\n",
        "    def add_image_slide(self, title, image_url):\n",
        "        \"\"\"\n",
        "        Add an image slide with a title and a centered image.\n",
        "        Downloads the image from the provided URL.\n",
        "        \"\"\"\n",
        "        # Use a blank layout if available; if not, fall back to layout 0.\n",
        "        if len(self.prs.slide_layouts) > 6:\n",
        "            blank_layout = self.prs.slide_layouts[6]\n",
        "        else:\n",
        "            blank_layout = self.prs.slide_layouts[0]\n",
        "        slide = self.prs.slides.add_slide(blank_layout)\n",
        "\n",
        "        # Add title textbox at the top of the slide.\n",
        "        title_box = slide.shapes.add_textbox(Inches(0.5), Inches(0.2), self.slide_width - Inches(1), Inches(1))\n",
        "        title_tf = title_box.text_frame\n",
        "        title_p = title_tf.add_paragraph()\n",
        "        title_p.text = title\n",
        "        title_p.font.size = Pt(32)\n",
        "        title_p.font.color.rgb = self.colors['title']\n",
        "\n",
        "        # Debug: Print the image URL being processed.\n",
        "        print(f\"Processing image URL: {image_url}\")\n",
        "\n",
        "        # Download the image.\n",
        "        response = requests.get(image_url)\n",
        "        if response.status_code != 200:\n",
        "            print(f\"Failed to download image. Status code: {response.status_code} for URL: {image_url}\")\n",
        "            return slide\n",
        "\n",
        "        image_data = BytesIO(response.content)\n",
        "\n",
        "        # Convert WEBP images to PNG if needed.\n",
        "        if image_url.lower().endswith('.webp'):\n",
        "            image_data = convert_webp_to_png(image_data)\n",
        "            if not image_data:\n",
        "                print(f\"Skipping invalid image: {image_url}\")\n",
        "                return slide\n",
        "\n",
        "        # Calculate image placement:\n",
        "        image_left = Inches(1)\n",
        "        image_top = Inches(1.5)\n",
        "        image_width = self.slide_width - Inches(2)  # full width minus margins\n",
        "        image_height = self.slide_height - Inches(2.5)  # leave margin at bottom\n",
        "\n",
        "        # Debug: Print placement details.\n",
        "        print(f\"Placing image at left: {image_left}, top: {image_top}, width: {image_width}, height: {image_height}\")\n",
        "\n",
        "        try:\n",
        "            slide.shapes.add_picture(image_data, image_left, image_top, width=image_width, height=image_height)\n",
        "            print(\"Image added successfully!\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error adding image: {e}\")\n",
        "\n",
        "        self.add_slide_number(slide)\n",
        "        return slide\n",
        "\n",
        "    def add_images_from_set(self, image_urls_set, title_prefix=\"Extra Image\"):\n",
        "        \"\"\"\n",
        "        Iterate over the set of image URLs and add each as a separate image slide.\n",
        "        \"\"\"\n",
        "        for idx, image_url in enumerate(image_urls_set, start=1):\n",
        "            slide_title = f\"{title_prefix} {idx}\"\n",
        "            self.add_image_slide(slide_title, image_url)\n",
        "\n",
        "    def process_json_to_ppt(self, json_data, query, image_urls=None):\n",
        "        \"\"\"Process JSON data and create PPT slides.\n",
        "           If image_urls (a list or set) is provided, insert an image slide after processing each content item.\n",
        "        \"\"\"\n",
        "        # If image_urls is a set, convert it to a list so we can pop from it.\n",
        "        if image_urls and isinstance(image_urls, set):\n",
        "            image_urls = list(image_urls)\n",
        "\n",
        "        # Add title slide.\n",
        "        self.add_title_slide(query.upper())\n",
        "\n",
        "        for section_key, section_data in json_data.items():\n",
        "            section_title = section_data['title']\n",
        "            for item in section_data['items']:\n",
        "                if 'content' in item:\n",
        "                    content_texts = []\n",
        "                    for content_item in item['content']:\n",
        "                        if isinstance(content_item, dict):\n",
        "                            if content_item['type'] == 'code':\n",
        "                                # If there is any pending text content, add it first.\n",
        "                                if content_texts:\n",
        "                                    self.add_content_slide(f\"{section_title} - {item['title']}\", content_texts)\n",
        "                                    content_texts = []\n",
        "                                self.add_code_slide(f\"{section_title} - {item['title']}\", content_item['content'])\n",
        "                            elif content_item['type'] == 'text':\n",
        "                                content_texts.append(content_item['content'])\n",
        "                    if content_texts:\n",
        "                        self.add_content_slide(f\"{section_title} - {item['title']}\", content_texts)\n",
        "\n",
        "                    # After processing the item, if an image URL is available, add an image slide.\n",
        "                    if image_urls and len(image_urls) > 0:\n",
        "                        next_image_url = image_urls.pop(0)\n",
        "                        self.add_image_slide(f\"{section_title} - {item['title']} Image\", next_image_url)\n",
        "\n",
        "                if 'subitems' in item:\n",
        "                    subitem_texts = []\n",
        "                    for subitem in item['subitems']:\n",
        "                        if 'content' in subitem:\n",
        "                            for content in subitem['content']:\n",
        "                                if isinstance(content, dict) and content['type'] == 'text':\n",
        "                                    title = f\"{subitem.get('title', '')}\"\n",
        "                                    if title:\n",
        "                                        subitem_texts.append(f\"{title}: {content['content']}\")\n",
        "                                    else:\n",
        "                                        subitem_texts.append(content['content'])\n",
        "                    if subitem_texts:\n",
        "                        self.add_content_slide(f\"{section_title} - {item['title']}\", subitem_texts, is_subsection=True)\n",
        "                        # Optionally insert an image slide after subitems, too.\n",
        "                        if image_urls and len(image_urls) > 0:\n",
        "                            next_image_url = image_urls.pop(0)\n",
        "                            self.add_image_slide(f\"{section_title} - {item['title']} Subitem Image\", next_image_url)\n",
        "\n",
        "    def save(self, filename):\n",
        "        \"\"\"Save the presentation.\"\"\"\n",
        "        self.prs.save(filename)\n",
        "\n",
        "def convert_webp_to_png(image_data):\n",
        "    \"\"\"Convert WEBP image data to PNG.\"\"\"\n",
        "    try:\n",
        "        with Image.open(image_data) as img:\n",
        "            png_buffer = BytesIO()\n",
        "            img.save(png_buffer, format=\"PNG\")\n",
        "            png_buffer.seek(0)\n",
        "            return png_buffer\n",
        "    except Exception as e:\n",
        "        print(f\"Error converting WEBP to PNG: {e}\")\n",
        "        return None\n",
        "\n",
        "def create_presentation(json_file_path, output_pptx_path, query, image_urls=None):\n",
        "    \"\"\"\n",
        "    Main function to create a presentation from JSON and intersperse extra image slides\n",
        "    from a set (or list) of image URLs.\n",
        "    \"\"\"\n",
        "    with open(json_file_path, 'r') as f:\n",
        "        json_data = json.load(f)\n",
        "\n",
        "    ppt_gen = PPTGenerator()\n",
        "    # Pass the image_urls container so they are inserted between content slides.\n",
        "    ppt_gen.process_json_to_ppt(json_data, query, image_urls=image_urls)\n",
        "\n",
        "    ppt_gen.save(output_pptx_path)\n",
        "    print(f\"Presentation saved as {output_pptx_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    output_filename = query.upper() + \".pptx\"\n",
        "\n",
        "\n",
        "\n",
        "    create_presentation(\"output_merged.json\", output_filename, query, images)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBlIurrNQzXb",
        "outputId": "80552df0-2e96-4a40-def3-454dbfb865a2"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing image URL: https://media.geeksforgeeks.org/wp-content/uploads/20230529103946/Bidirectional-LSTM-(1)-660.jpg\n",
            "Placing image at left: 914400, top: 1371600, width: 10363200, height: 4572000\n",
            "Image added successfully!\n",
            "Processing image URL: https://media.geeksforgeeks.org/wp-content/uploads/20240425175947/Capture.PNG\n",
            "Placing image at left: 914400, top: 1371600, width: 10363200, height: 4572000\n",
            "Image added successfully!\n",
            "Processing image URL: https://media.geeksforgeeks.org/wp-content/uploads/20240208053129/lstm.webp\n",
            "Placing image at left: 914400, top: 1371600, width: 10363200, height: 4572000\n",
            "Image added successfully!\n",
            "Processing image URL: https://media.geeksforgeeks.org/wp-content/uploads/20240208104902/bruh.webp\n",
            "Placing image at left: 914400, top: 1371600, width: 10363200, height: 4572000\n",
            "Image added successfully!\n",
            "Presentation saved as LSTM.pptx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from pptx import Presentation\n",
        "from pptx.util import Inches, Pt\n",
        "from pptx.enum.text import PP_ALIGN\n",
        "from pptx.dml.color import RGBColor\n",
        "from pptx.enum.text import MSO_AUTO_SIZE\n",
        "\n",
        "class PPTGenerator:\n",
        "    def __init__(self, template_path):\n",
        "        print(f\"Initializing PPT Generator with template: {template_path}\")\n",
        "        self.prs = Presentation(template_path)\n",
        "        self.slide_width = self.prs.slide_width\n",
        "        self.slide_height = self.prs.slide_height\n",
        "        self.slide_count = 0\n",
        "\n",
        "        # Color scheme\n",
        "        self.colors = {\n",
        "            'title': RGBColor(44, 62, 80),      # Dark blue\n",
        "            'subtitle': RGBColor(52, 73, 94),    # Lighter blue\n",
        "            'body': RGBColor(44, 62, 80),        # Dark blue\n",
        "            'code': RGBColor(46, 204, 113),      # Green\n",
        "            'slide_number': RGBColor(149, 165, 166)  # Gray\n",
        "        }\n",
        "\n",
        "    def add_slide_number(self, slide):\n",
        "        \"\"\"Add slide number to the bottom right corner\"\"\"\n",
        "        self.slide_count += 1\n",
        "        txBox = slide.shapes.add_textbox(\n",
        "            Inches(9), Inches(6.5), Inches(1), Inches(0.5))\n",
        "        tf = txBox.text_frame\n",
        "        p = tf.paragraphs[0]\n",
        "        p.text = f\"Slide {self.slide_count}\"\n",
        "        p.alignment = PP_ALIGN.RIGHT\n",
        "        p.font.size = Pt(12)\n",
        "        p.font.color.rgb = self.colors['slide_number']\n",
        "\n",
        "    def add_title_slide(self, title):\n",
        "        \"\"\"Add title slide\"\"\"\n",
        "        print(f\"Adding title slide: {title}\")\n",
        "        slide_layout = self.prs.slide_layouts[0]\n",
        "        slide = self.prs.slides.add_slide(slide_layout)\n",
        "\n",
        "        title_shape = slide.shapes.title\n",
        "        title_shape.text = title\n",
        "        title_shape.text_frame.paragraphs[0].font.color.rgb = self.colors['title']\n",
        "        title_shape.text_frame.paragraphs[0].font.size = Pt(44)\n",
        "\n",
        "        self.add_slide_number(slide)\n",
        "        return slide\n",
        "\n",
        "    def format_bullet_point(self, paragraph, level=0):\n",
        "        \"\"\"Format bullet point with proper indentation and style\"\"\"\n",
        "        paragraph.level = level\n",
        "        paragraph.font.size = Pt(25 - level)  # Decrease font size for deeper levels\n",
        "        paragraph.font.color.rgb = self.colors['body']\n",
        "        return paragraph\n",
        "\n",
        "    def add_content_slide(self, title, content_items, is_subsection=False):\n",
        "        \"\"\"Add content slide with proper bullet points and overflow management\"\"\"\n",
        "        print(f\"Adding content slide: {title}\")\n",
        "        slide_layout = self.prs.slide_layouts[1]\n",
        "        current_slide = self.prs.slides.add_slide(slide_layout)\n",
        "\n",
        "        # Add title\n",
        "        title_shape = current_slide.shapes.title\n",
        "        title_shape.text = title\n",
        "        title_shape.text_frame.paragraphs[0].font.color.rgb = self.colors['title']\n",
        "        title_shape.text_frame.paragraphs[0].font.size = Pt(32)\n",
        "\n",
        "        # Add content\n",
        "        content_shape = current_slide.placeholders[1]\n",
        "        tf = content_shape.text_frame\n",
        "        tf.word_wrap = True\n",
        "        tf.clear()\n",
        "\n",
        "        current_height = 0\n",
        "        max_height = Inches(5)\n",
        "\n",
        "        for item in content_items:\n",
        "            text_height = len(str(item).split()) * Pt(25) * 0.3\n",
        "\n",
        "            if current_height + text_height > max_height:\n",
        "                current_slide = self.prs.slides.add_slide(slide_layout)\n",
        "                title_shape = current_slide.shapes.title\n",
        "                title_shape.text = f\"{title} (continued)\"\n",
        "                title_shape.text_frame.paragraphs[0].font.color.rgb = self.colors['title']\n",
        "                title_shape.text_frame.paragraphs[0].font.size = Pt(32)\n",
        "\n",
        "                content_shape = current_slide.placeholders[1]\n",
        "                tf = content_shape.text_frame\n",
        "                tf.word_wrap = True\n",
        "                current_height = 0\n",
        "                self.add_slide_number(current_slide)\n",
        "\n",
        "            p = tf.add_paragraph()\n",
        "            p.text = str(item)\n",
        "            self.format_bullet_point(p, 1 if is_subsection else 0)\n",
        "            current_height += text_height\n",
        "\n",
        "        self.add_slide_number(current_slide)\n",
        "        return current_slide\n",
        "\n",
        "    def add_code_slide(self, title, code):\n",
        "        \"\"\"Add code slide with proper formatting\"\"\"\n",
        "        print(f\"Adding code slide: {title}\")\n",
        "        slide_layout = self.prs.slide_layouts[1]\n",
        "        slide = self.prs.slides.add_slide(slide_layout)\n",
        "\n",
        "        title_shape = slide.shapes.title\n",
        "        title_shape.text = title\n",
        "        title_shape.text_frame.paragraphs[0].font.color.rgb = self.colors['title']\n",
        "        title_shape.text_frame.paragraphs[0].font.size = Pt(32)\n",
        "\n",
        "        left = Inches(2)\n",
        "        top = Inches(2.6)\n",
        "        width = Inches(8)\n",
        "        height = Inches(5)\n",
        "\n",
        "        textbox = slide.shapes.add_textbox(left, top, width, height)\n",
        "        tf = textbox.text_frame\n",
        "        tf.word_wrap = True\n",
        "\n",
        "        code_lines = str(code).split('\\n')\n",
        "        lines_per_slide = 20\n",
        "\n",
        "        for i in range(0, len(code_lines), lines_per_slide):\n",
        "            if i > 0:\n",
        "                slide = self.prs.slides.add_slide(slide_layout)\n",
        "                title_shape = slide.shapes.title\n",
        "                title_shape.text = f\"{title} (continued)\"\n",
        "                title_shape.text_frame.paragraphs[0].font.color.rgb = self.colors['title']\n",
        "                textbox = slide.shapes.add_textbox(left, top, width, height)\n",
        "                tf = textbox.text_frame\n",
        "                tf.word_wrap = True\n",
        "\n",
        "            chunk = '\\n'.join(code_lines[i:i + lines_per_slide])\n",
        "            p = tf.add_paragraph()\n",
        "            p.text = chunk\n",
        "            p.font.name = 'Courier New'\n",
        "            p.font.size = Pt(11)\n",
        "            p.font.color.rgb = self.colors['code']\n",
        "\n",
        "            self.add_slide_number(slide)\n",
        "\n",
        "        return slide\n",
        "\n",
        "    def add_equation_slide(self, title, equations):\n",
        "        \"\"\"Add slide with equation images\"\"\"\n",
        "        print(f\"\\nAdding equation slide: {title}\")\n",
        "        print(f\"Number of equations to add: {len(equations)}\")\n",
        "\n",
        "        slide_layout = self.prs.slide_layouts[1]\n",
        "        slide = self.prs.slides.add_slide(slide_layout)\n",
        "\n",
        "        title_shape = slide.shapes.title\n",
        "        title_shape.text = title\n",
        "        title_shape.text_frame.paragraphs[0].font.color.rgb = self.colors['title']\n",
        "        title_shape.text_frame.paragraphs[0].font.size = Pt(32)\n",
        "\n",
        "        left = Inches(2)\n",
        "        top = Inches(2)\n",
        "        max_height = Inches(5)\n",
        "        current_top = top\n",
        "\n",
        "        for equation_path in equations:\n",
        "            print(f\"Attempting to add equation from: {equation_path}\")\n",
        "            try:\n",
        "                if not os.path.exists(equation_path):\n",
        "                    print(f\"Error: File not found - {equation_path}\")\n",
        "                    continue\n",
        "\n",
        "                img = slide.shapes.add_picture(\n",
        "                    equation_path,\n",
        "                    left,\n",
        "                    current_top,\n",
        "                    width=Inches(6)\n",
        "                )\n",
        "                print(f\"Successfully added equation image: {equation_path}\")\n",
        "                current_top += img.height + Inches(0.5)\n",
        "\n",
        "                if current_top > top + max_height:\n",
        "                    print(\"Creating new slide for overflow equations\")\n",
        "                    slide = self.prs.slides.add_slide(slide_layout)\n",
        "                    title_shape = slide.shapes.title\n",
        "                    title_shape.text = f\"{title} (continued)\"\n",
        "                    title_shape.text_frame.paragraphs[0].font.color.rgb = self.colors['title']\n",
        "                    title_shape.text_frame.paragraphs[0].font.size = Pt(32)\n",
        "                    current_top = top\n",
        "                    self.add_slide_number(slide)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error adding equation image {equation_path}: {str(e)}\")\n",
        "                print(f\"Exception type: {type(e)}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "\n",
        "        self.add_slide_number(slide)\n",
        "        return slide\n",
        "\n",
        "    def process_json_to_ppt(self, json_data, title):\n",
        "        \"\"\"Process JSON data and create PPT slides\"\"\"\n",
        "        print(\"\\nStarting PPT Generation...\")\n",
        "        print(f\"Processing title: {title}\")\n",
        "\n",
        "        self.add_title_slide(title)\n",
        "\n",
        "        for section_key, section_data in json_data.items():\n",
        "            print(f\"\\nProcessing section: {section_key}\")\n",
        "\n",
        "            if section_key == \"metadata\":\n",
        "                print(\"Skipping metadata section\")\n",
        "                continue\n",
        "\n",
        "            section_title = section_data['title']\n",
        "            print(f\"Section title: {section_title}\")\n",
        "\n",
        "            for item in section_data['items']:\n",
        "                print(f\"\\nProcessing item: {item.get('title', 'Untitled')}\")\n",
        "\n",
        "                if 'content' in item:\n",
        "                    content_texts = []\n",
        "                    equation_images = []\n",
        "\n",
        "                    for content_item in item['content']:\n",
        "                        if isinstance(content_item, dict):\n",
        "                            content_type = content_item.get('type', 'unknown')\n",
        "                            print(f\"Found content of type: {content_type}\")\n",
        "\n",
        "                            if content_type == 'code':\n",
        "                                if content_texts:\n",
        "                                    self.add_content_slide(f\"{section_title} - {item.get('title', '')}\", content_texts)\n",
        "                                    content_texts = []\n",
        "                                self.add_code_slide(f\"{section_title} - {item.get('title', '')}\", content_item['content'])\n",
        "\n",
        "                            elif content_type == 'equation_image':\n",
        "                                print(f\"Found equation image: {content_item['content']}\")\n",
        "                                equation_images.append(content_item['content'])\n",
        "\n",
        "                            elif content_type == 'text':\n",
        "                                content_texts.append(content_item['content'])\n",
        "\n",
        "                    if content_texts:\n",
        "                        print(f\"Adding content slide with {len(content_texts)} text items\")\n",
        "                        self.add_content_slide(f\"{section_title} - {item.get('title', '')}\", content_texts)\n",
        "\n",
        "                    if equation_images:\n",
        "                        print(f\"Adding equation slide with {len(equation_images)} equations\")\n",
        "                        self.add_equation_slide(f\"{section_title} - {item.get('title', '')}\", equation_images)\n",
        "                        equation_images = []\n",
        "\n",
        "                if 'subitems' in item:\n",
        "                    print(f\"Processing subitems for: {item.get('title', 'Untitled')}\")\n",
        "                    subitem_texts = []\n",
        "                    subitem_equations = []\n",
        "\n",
        "                    for subitem in item['subitems']:\n",
        "                        print(f\"Processing subitem: {subitem.get('title', 'Untitled')}\")\n",
        "                        if 'content' in subitem:\n",
        "                            for content in subitem['content']:\n",
        "                                if isinstance(content, dict):\n",
        "                                    content_type = content.get('type', 'unknown')\n",
        "                                    print(f\"Found subitem content of type: {content_type}\")\n",
        "\n",
        "                                    if content_type == 'equation_image':\n",
        "                                        print(f\"Found subitem equation: {content['content']}\")\n",
        "                                        subitem_equations.append(content['content'])\n",
        "                                    elif content_type == 'text':\n",
        "                                        title = subitem.get('title', '')\n",
        "                                        if title:\n",
        "                                            subitem_texts.append(f\"{title}: {content['content']}\")\n",
        "                                        else:\n",
        "                                            subitem_texts.append(content['content'])\n",
        "\n",
        "                    if subitem_texts:\n",
        "                        print(f\"Adding subitem content slide with {len(subitem_texts)} items\")\n",
        "                        self.add_content_slide(f\"{section_title} - {item.get('title', '')}\",\n",
        "                                            subitem_texts,\n",
        "                                            is_subsection=True)\n",
        "\n",
        "                    if subitem_equations:\n",
        "                        print(f\"Adding subitem equation slide with {len(subitem_equations)} equations\")\n",
        "                        self.add_equation_slide(f\"{section_title} - {item.get('title', '')}\",\n",
        "                                             subitem_equations)\n",
        "\n",
        "        print(\"\\nPPT Generation completed!\")\n",
        "\n",
        "    def save(self, filename):\n",
        "        \"\"\"Save the presentation\"\"\"\n",
        "        print(f\"\\nSaving presentation to: {filename}\")\n",
        "        self.prs.save(filename)\n",
        "        print(\"Presentation saved successfully!\")\n",
        "\n",
        "def create_presentation(json_file_path, output_pptx_path, title, template_path):\n",
        "    \"\"\"Main function to create presentation from JSON\"\"\"\n",
        "    print(f\"\\nStarting presentation creation...\")\n",
        "    print(f\"Input JSON: {json_file_path}\")\n",
        "    print(f\"Output PPTX: {output_pptx_path}\")\n",
        "    print(f\"Template: {template_path}\")\n",
        "\n",
        "    try:\n",
        "        with open(json_file_path, 'r') as f:\n",
        "            json_data = json.load(f)\n",
        "            print(\"JSON file loaded successfully\")\n",
        "            print(f\"Number of sections: {len(json_data)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading JSON file: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        ppt_gen = PPTGenerator(template_path)\n",
        "        print(\"PPT Generator initialized\")\n",
        "\n",
        "        ppt_gen.process_json_to_ppt(json_data, title)\n",
        "        print(\"Content processing completed\")\n",
        "\n",
        "        ppt_gen.save(output_pptx_path)\n",
        "        print(f\"Presentation saved as {output_pptx_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating presentation: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "# Usage example\n",
        "if __name__ == \"__main__\":\n",
        "    template_path = \"/content/Crop.pptx\"  # Update this path to your template\n",
        "    json_file_path = \"output_updated.json\"\n",
        "    output_pptx_path = query.upper()+\".pptx\"\n",
        "    presentation_title = query.upper()\n",
        "\n",
        "    create_presentation(\n",
        "        json_file_path=json_file_path,\n",
        "        output_pptx_path=output_pptx_path,\n",
        "        title=presentation_title,\n",
        "        template_path=template_path\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qplZM7Zppla",
        "outputId": "221149b3-d05b-4058-cb9e-a367fc0a0456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting presentation creation...\n",
            "Input JSON: output_updated.json\n",
            "Output PPTX: MUTEX LOCKS.pptx\n",
            "Template: /content/Crop.pptx\n",
            "JSON file loaded successfully\n",
            "Number of sections: 7\n",
            "Initializing PPT Generator with template: /content/Crop.pptx\n",
            "PPT Generator initialized\n",
            "\n",
            "Starting PPT Generation...\n",
            "Processing title: MUTEX LOCKS\n",
            "Adding title slide: MUTEX LOCKS\n",
            "\n",
            "Processing section: Section 1\n",
            "Section title: Concept Overview\n",
            "\n",
            "Processing item: Core definition and purpose\n",
            "Found content of type: text\n",
            "Adding content slide with 1 text items\n",
            "Adding content slide: Concept Overview - Core definition and purpose\n",
            "\n",
            "Processing item: Key principles\n",
            "Found content of type: text\n",
            "Adding content slide with 1 text items\n",
            "Adding content slide: Concept Overview - Key principles\n",
            "\n",
            "Processing item: Relationship to broader computing concepts\n",
            "Found content of type: text\n",
            "Adding content slide with 1 text items\n",
            "Adding content slide: Concept Overview - Relationship to broader computing concepts\n",
            "\n",
            "Processing section: Section 2\n",
            "Section title: Technical Components\n",
            "\n",
            "Processing item: Primary elements and their roles\n",
            "Processing subitems for: Primary elements and their roles\n",
            "Processing subitem: Lock Table\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Lock Manager\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Transactions\n",
            "Found subitem content of type: text\n",
            "Adding subitem content slide with 3 items\n",
            "Adding content slide: Technical Components - Primary elements and their roles\n",
            "\n",
            "Processing item: Relationships and interactions\n",
            "Found content of type: text\n",
            "Adding content slide with 1 text items\n",
            "Adding content slide: Technical Components - Relationships and interactions\n",
            "\n",
            "Processing item: Implementation details\n",
            "Found content of type: text\n",
            "Adding content slide with 1 text items\n",
            "Adding content slide: Technical Components - Implementation details\n",
            "\n",
            "Processing item: Core algorithms/procedures\n",
            "Processing subitems for: Core algorithms/procedures\n",
            "Processing subitem: Read_Lock\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Write_Lock\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Unlock\n",
            "Found subitem content of type: text\n",
            "Adding subitem content slide with 3 items\n",
            "Adding content slide: Technical Components - Core algorithms/procedures\n",
            "\n",
            "Processing section: Section 3\n",
            "Section title: Working Mechanism\n",
            "\n",
            "Processing item: Step-by-step operational flow\n",
            "Processing subitems for: Step-by-step operational flow\n",
            "Processing subitem: Untitled\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Untitled\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Untitled\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Untitled\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Untitled\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Untitled\n",
            "Found subitem content of type: text\n",
            "Adding subitem content slide with 6 items\n",
            "Adding content slide: Working Mechanism - Step-by-step operational flow\n",
            "\n",
            "Processing item: Critical processes and transformations\n",
            "Processing subitems for: Critical processes and transformations\n",
            "Processing subitem: Lock Acquisition\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Lock Release\n",
            "Found subitem content of type: text\n",
            "Processing subitem: State Transition\n",
            "Found subitem content of type: text\n",
            "Adding subitem content slide with 3 items\n",
            "Adding content slide: Working Mechanism - Critical processes and transformations\n",
            "\n",
            "Processing item: Resource management\n",
            "Found content of type: text\n",
            "Adding content slide with 1 text items\n",
            "Adding content slide: Working Mechanism - Resource management\n",
            "\n",
            "Processing item: Exception handling\n",
            "Found content of type: text\n",
            "Adding content slide with 1 text items\n",
            "Adding content slide: Working Mechanism - Exception handling\n",
            "\n",
            "Processing section: Section 4\n",
            "Section title: Implementation Example\n",
            "\n",
            "Processing item: Use case scenario\n",
            "Found content of type: text\n",
            "Adding content slide with 1 text items\n",
            "Adding content slide: Implementation Example - Use case scenario\n",
            "\n",
            "Processing item: Code implementation or technical design\n",
            "Found content of type: code\n",
            "Adding code slide: Implementation Example - Code implementation or technical design\n",
            "\n",
            "Processing item: Step-by-step execution\n",
            "Processing subitems for: Step-by-step execution\n",
            "Processing subitem: Untitled\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Untitled\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Untitled\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Untitled\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Untitled\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Untitled\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Untitled\n",
            "Found subitem content of type: text\n",
            "Adding subitem content slide with 7 items\n",
            "Adding content slide: Implementation Example - Step-by-step execution\n",
            "\n",
            "Processing section: Section 5\n",
            "Section title: Best Practices\n",
            "\n",
            "Processing item: Design considerations\n",
            "Processing subitems for: Design considerations\n",
            "Processing subitem: Untitled\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Untitled\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Untitled\n",
            "Found subitem content of type: text\n",
            "Adding subitem content slide with 3 items\n",
            "Adding content slide: Best Practices - Design considerations\n",
            "\n",
            "Processing item: Optimization techniques\n",
            "Processing subitems for: Optimization techniques\n",
            "Processing subitem: Untitled\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Untitled\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Untitled\n",
            "Found subitem content of type: text\n",
            "Adding subitem content slide with 3 items\n",
            "Adding content slide: Best Practices - Optimization techniques\n",
            "\n",
            "Processing item: Common pitfalls\n",
            "Processing subitems for: Common pitfalls\n",
            "Processing subitem: Starvation\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Deadlocks\n",
            "Found subitem content of type: text\n",
            "Adding subitem content slide with 2 items\n",
            "Adding content slide: Best Practices - Common pitfalls\n",
            "\n",
            "Processing item: Performance implications\n",
            "Processing subitems for: Performance implications\n",
            "Processing subitem: Untitled\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Untitled\n",
            "Found subitem content of type: text\n",
            "Adding subitem content slide with 2 items\n",
            "Adding content slide: Best Practices - Performance implications\n",
            "\n",
            "Processing section: Section 6\n",
            "Section title: Applications\n",
            "\n",
            "Processing item: Real-world use cases\n",
            "Processing subitems for: Real-world use cases\n",
            "Processing subitem: Database Systems\n",
            "Found subitem content of type: text\n",
            "Processing subitem: File Systems\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Web Applications\n",
            "Found subitem content of type: text\n",
            "Adding subitem content slide with 3 items\n",
            "Adding content slide: Applications - Real-world use cases\n",
            "\n",
            "Processing item: Industry applications\n",
            "Processing subitems for: Industry applications\n",
            "Processing subitem: Banking and Finance\n",
            "Found subitem content of type: text\n",
            "Processing subitem: E-commerce\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Social Media\n",
            "Found subitem content of type: text\n",
            "Adding subitem content slide with 3 items\n",
            "Adding content slide: Applications - Industry applications\n",
            "\n",
            "Processing item: Integration patterns\n",
            "Processing subitems for: Integration patterns\n",
            "Processing subitem: Lock Striping\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Optimistic Concurrency Control\n",
            "Found subitem content of type: text\n",
            "Adding subitem content slide with 2 items\n",
            "Adding content slide: Applications - Integration patterns\n",
            "\n",
            "Processing item: Variations and alternatives\n",
            "Processing subitems for: Variations and alternatives\n",
            "Processing subitem: Semaphore\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Monitor\n",
            "Found subitem content of type: text\n",
            "Adding subitem content slide with 2 items\n",
            "Adding content slide: Applications - Variations and alternatives\n",
            "\n",
            "Processing section: Section 7\n",
            "Section title: Evaluation\n",
            "\n",
            "Processing item: Performance metrics\n",
            "Processing subitems for: Performance metrics\n",
            "Processing subitem: Throughput\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Response Time\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Lock Wait Time\n",
            "Found subitem content of type: text\n",
            "Processing subitem: Deadlock Frequency\n",
            "Found subitem content of type: text\n",
            "Adding subitem content slide with 4 items\n",
            "Adding content slide: Evaluation - Performance metrics\n",
            "\n",
            "Processing item: Testing approaches\n",
            "Processing subitems for: Testing approaches\n",
            "Processing subitem: Untitled\n",
            "Found subitem content of type: text\n",
            "Adding subitem content slide with 1 items\n",
            "Adding content slide: Evaluation - Testing approaches\n",
            "\n",
            "PPT Generation completed!\n",
            "Content processing completed\n",
            "\n",
            "Saving presentation to: MUTEX LOCKS.pptx\n",
            "Presentation saved successfully!\n",
            "Presentation saved as MUTEX LOCKS.pptx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convert text file to .tex and then .tex to pdf"
      ],
      "metadata": {
        "id": "ycUjp9UH_dUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "class LatexConverter:\n",
        "    def __init__(self):\n",
        "        self.template = r\"\"\"\\documentclass{article}\n",
        "\\usepackage{amsmath}\n",
        "\\usepackage{listings}\n",
        "\\usepackage{xcolor}\n",
        "\\usepackage{enumitem}\n",
        "\\usepackage{titlesec}\n",
        "\\usepackage{geometry}\n",
        "\n",
        "\\geometry{\n",
        "    a4paper,\n",
        "    margin=1in\n",
        "}\n",
        "\n",
        "% Section formatting\n",
        "\\titleformat{\\section}\n",
        "    {\\Large\\bfseries}\n",
        "    {\\thesection}\n",
        "    {1em}\n",
        "    {}\n",
        "\n",
        "\\titleformat{\\subsection}\n",
        "    {\\large\\bfseries}\n",
        "    {\\thesubsection}\n",
        "    {1em}\n",
        "    {}\n",
        "\n",
        "% List settings\n",
        "\\setlist[enumerate]{label=\\arabic*.}\n",
        "\n",
        "% Code listing settings\n",
        "\\lstset{\n",
        "    backgroundcolor=\\color{gray!10},\n",
        "    basicstyle=\\ttfamily\\footnotesize,\n",
        "    breaklines=true,\n",
        "    frame=single,\n",
        "    numbers=left,\n",
        "    numberstyle=\\tiny,\n",
        "    keywordstyle=\\color{blue},\n",
        "    commentstyle=\\color{green!60!black},\n",
        "    stringstyle=\\color{red},\n",
        "    showstringspaces=false,\n",
        "    tabsize=4\n",
        "}\n",
        "\n",
        "\\begin{document}\n",
        "\\pagestyle{plain}\n",
        "\"\"\"\n",
        "\n",
        "    def _clean_text(self, text: str) -> str:\n",
        "        \"\"\"Clean text while preserving math content.\"\"\"\n",
        "        if '$' in text:  # Contains math expressions\n",
        "            return text\n",
        "\n",
        "        text = text.replace('\\\\', r'\\textbackslash{}')\n",
        "        text = text.replace('_', r'\\_')\n",
        "        text = text.replace('^', r'\\^{}')\n",
        "        text = text.replace('~', r'\\textasciitilde{}')\n",
        "        text = text.replace('#', r'\\#')\n",
        "        text = text.replace('%', r'\\%')\n",
        "        text = text.replace('&', r'\\&')\n",
        "        text = text.replace('<', r'\\textless{}')\n",
        "        text = text.replace('>', r'\\textgreater{}')\n",
        "\n",
        "        # Handle bold text\n",
        "        text = re.sub(r'\\*\\*(.*?)\\*\\*', r'\\\\textbf{\\1}', text)\n",
        "\n",
        "        return text\n",
        "\n",
        "    def convert_to_tex(self, content: str) -> str:\n",
        "        \"\"\"Convert markdown content to LaTeX.\"\"\"\n",
        "        output = [self.template]\n",
        "        lines = content.split('\\n')\n",
        "        in_code_block = False\n",
        "        i = 0\n",
        "\n",
        "        while i < len(lines):\n",
        "            line = lines[i].strip()\n",
        "\n",
        "            if not line:\n",
        "                i += 1\n",
        "                continue\n",
        "\n",
        "            # Handle section headers\n",
        "            if line.startswith('## '):\n",
        "                title = re.search(r'\\*\\*(.*?)\\*\\*', line)\n",
        "                if title:\n",
        "                    output.append(f\"\\\\section{{{title.group(1)}}}\")\n",
        "                i += 1\n",
        "                continue\n",
        "\n",
        "            # Handle code blocks\n",
        "            if line.startswith('```'):\n",
        "                if 'python' in line.lower():\n",
        "                    output.append('\\\\begin{lstlisting}[language=Python]')\n",
        "                else:\n",
        "                    output.append('\\\\begin{lstlisting}')\n",
        "                i += 1\n",
        "                while i < len(lines) and not lines[i].strip().startswith('```'):\n",
        "                    output.append(lines[i])\n",
        "                    i += 1\n",
        "                output.append('\\\\end{lstlisting}')\n",
        "                i += 1\n",
        "                continue\n",
        "\n",
        "            # Handle numbered lists\n",
        "            if re.match(r'^\\d+\\.\\s', line):\n",
        "                output.append('\\\\begin{enumerate}[resume*]')\n",
        "                while i < len(lines) and re.match(r'^\\d+\\.\\s', lines[i].strip()):\n",
        "                    item = re.sub(r'^\\d+\\.\\s', '', lines[i].strip())\n",
        "                    item = self._clean_text(item)\n",
        "                    output.append(f\"\\\\item {item}\")\n",
        "                    i += 1\n",
        "                output.append('\\\\end{enumerate}')\n",
        "                continue\n",
        "\n",
        "            # Regular line\n",
        "            text = self._clean_text(line)\n",
        "            if text:\n",
        "                output.append(text + \"\\\\\\\\\")\n",
        "            i += 1\n",
        "\n",
        "        output.append(\"\\\\end{document}\")\n",
        "        return '\\n'.join(output)\n",
        "\n",
        "    def create_pdf(self, content: str, output_filename: str = \"output\") -> str:\n",
        "        \"\"\"Convert content to LaTeX and compile to PDF.\"\"\"\n",
        "        try:\n",
        "            # Convert content to LaTeX\n",
        "            tex_content = self.convert_to_tex(content)\n",
        "\n",
        "            # Write TEX file\n",
        "            tex_file = f\"{output_filename}.tex\"\n",
        "            with open(tex_file, \"w\", encoding='utf-8') as f:\n",
        "                f.write(tex_content)\n",
        "\n",
        "            # Compile twice for references\n",
        "            for _ in range(2):\n",
        "                result = subprocess.run(\n",
        "                    ['pdflatex', '-interaction=nonstopmode', tex_file],\n",
        "                    capture_output=True,\n",
        "                    text=True,\n",
        "                    check=False\n",
        "                )\n",
        "                if result.returncode != 0:\n",
        "                    with open(f\"{output_filename}.log\", \"r\") as f:\n",
        "                        log = f.read()\n",
        "                    raise RuntimeError(f\"PDF compilation failed. Check {output_filename}.log for details\")\n",
        "\n",
        "            # Clean up auxiliary files\n",
        "            if os.path.exists(f\"{output_filename}.pdf\"):\n",
        "                for ext in ['.aux', '.out']:\n",
        "                    if os.path.exists(f\"{output_filename}{ext}\"):\n",
        "                        os.remove(f\"{output_filename}{ext}\")\n",
        "                return f\"{output_filename}.pdf\"\n",
        "            else:\n",
        "                raise RuntimeError(\"PDF compilation failed\")\n",
        "\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"An error occurred: {str(e)}\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        converter = LatexConverter()\n",
        "\n",
        "        # Read input file\n",
        "        with open(\"content.txt\", \"r\", encoding='utf-8') as f:\n",
        "            content = f.read()\n",
        "\n",
        "        # Convert to PDF\n",
        "        pdf_file = converter.create_pdf(content, query.upper())\n",
        "        print(f\"Successfully created {pdf_file}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")"
      ],
      "metadata": {
        "id": "CRhX7W5D_Hqi",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343160bb-fa25-4c55-dbec-4d790c6a75d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: An error occurred: PDF compilation failed. Check SVM.log for details\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N9Jz8aSSAGoM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}